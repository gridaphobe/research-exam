
@article{seidel_metadata_2012,
	title = {Metadata Management in Scientific Computing},
	volume = {3},
	url = {http://shodor.org/media/content/jocse/volume3/issue2/seidel_2012},
	abstract = {Complex scientific codes and the datasets they generate are in need of a sophisticated categorization environment that allows the community to store, search, and enhance metadata in an open, dynamic system. Currently, data is often presented in a read-only format, distilled and curated by a select group of researchers. We envision a more open and dynamic system, where authors can publish their data in a writeable format, allowing users to annotate the datasets with their own comments and data. This would enable the scientific community to collaborate on a higher level than before, where researchers could for example annotate a published dataset with their citations. Such a system would require a complete set of permissions to ensure that any individual's data cannot be altered by others unless they specifically allow it. For this reason datasets and codes are generally presented read-only, to protect the author's data; however, this also prevents the type of social revolutions that the private sector has seen with Facebook and Twitter. In this paper, we present an alternative method of publishing codes and datasets, based on Fluidinfo, which is an openly writeable and social metadata engine. We will use the specific example of the Einstein Toolkit, a shared scientific code built using the Cactus Framework, to illustrate how the code's metadata may be published in writeable form via Fluidinfo.},
	number = {2},
	urldate = {2015-01-26},
	journal = {Journal of Computational Science Education},
	author = {Seidel, Eric L.},
	month = dec,
	year = {2012},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv.org Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5EXKH9XK/1203.html:text/html;Seidel - 2012 - Metadata Management in Scientific Computing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BE9FMWU2/Seidel - 2012 - Metadata Management in Scientific Computing.pdf:application/pdf}
}

@incollection{christiansen_easycheck_2008,
	series = {Lecture Notes in Computer Science},
	title = {{EasyCheck} — Test Data for Free},
	copyright = {©2008 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-78968-0, 978-3-540-78969-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-78969-7_23},
	abstract = {We present a lightweight, automated tool for specification-based testing of declarative programs written in the functional logic programming language Curry and emphasize the usefulness of logic features in its implementation and use. Free variables, nondeterminism and encapsulated search turn out to be elegant and powerful means to express test-data generation.},
	number = {4989},
	urldate = {2014-06-16},
	booktitle = {Functional and Logic Programming},
	publisher = {Springer Berlin Heidelberg},
	author = {Christiansen, Jan and Fischer, Sebastian},
	editor = {Garrigue, Jacques and Hermenegildo, Manuel V.},
	month = jan,
	year = {2008},
	keywords = {\_tablet, Artificial Intelligence (incl. Robotics), Curry, Encapsulated Search, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Nondeterminism, Programming Languages, Compilers, Interpreters, Programming Techniques, Testing},
	pages = {322--336},
	file = {Christiansen and Fischer - 2008 - EasyCheck — Test Data for Free.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/NZPXB44S/Christiansen and Fischer - 2008 - EasyCheck — Test Data for Free.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/VZDTRF3G/978-3-540-78969-7_23.html:text/html}
}

@inproceedings{jhala_path_2005,
	address = {New York, {NY}, {USA}},
	series = {{PLDI} '05},
	title = {Path Slicing},
	isbn = {1-59593-056-6},
	url = {http://doi.acm.org/10.1145/1065010.1065016},
	doi = {10.1145/1065010.1065016},
	abstract = {We present a new technique, path slicing, that takes as input a possibly infeasible path to a target location, and eliminates all the operations that are irrelevant towards the reachability of the target location. A path slice is a subsequence of the original path whose infeasibility guarantees the infeasibility of the original path, and whose feasibility guarantees the existence of some feasible variant of the given path that reaches the target location even though the given path may itself be infeasible. Our method combines the ability of program slicing to look at several program paths, with the precision that dynamic slicing enjoys by focusing on a single path. We have implemented Path Slicing to analyze possible counterexamples returned by the software model checker Blast. We show its effectiveness in drastically reducing the size of the counterexamples to less than 1\% of their original size. This enables the precise verification of application programs (upto 100KLOC), by allowing the analysis to focus on the part of the counterexample that is relevant to the property being checked.},
	urldate = {2015-01-24},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Jhala, Ranjit and Majumdar, Rupak},
	year = {2005},
	keywords = {counterexample analysis, program slicing},
	pages = {38--47},
	file = {Jhala and Majumdar - 2005 - Path Slicing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/VP8QFA53/Jhala and Majumdar - 2005 - Path Slicing.pdf:application/pdf}
}

@inproceedings{visser_test_2004,
	address = {New York, {NY}, {USA}},
	series = {{ISSTA} '04},
	title = {Test Input Generation with Java {PathFinder}},
	isbn = {1-58113-820-2},
	url = {http://doi.acm.org/10.1145/1007512.1007526},
	doi = {10.1145/1007512.1007526},
	abstract = {We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures. We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java {TreeMap} library, using the Java {PathFinder} model checker. Three different test generation techniques will be introduced and compared, namely, straight model checking of the code, model checking used in a black-box fashion to generate all inputs up to a fixed size, and lastly, model checking used during white-box test input generation. The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data, taking into account complex method preconditions.},
	urldate = {2015-01-23},
	booktitle = {Proceedings of the 2004 {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis},
	publisher = {{ACM}},
	author = {Visser, Willem and Pǎsǎreanu, Corina S. and Khurshid, Sarfraz},
	year = {2004},
	keywords = {coverage, model checking, red-black trees, symbolic execution, testing object-oriented programs},
	pages = {97--107},
	file = {Visser et al. - 2004 - Test Input Generation with Java PathFinder.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/HQVUM56P/Visser et al. - 2004 - Test Input Generation with Java PathFinder.pdf:application/pdf}
}

@inproceedings{naylor_finding_2007,
	series = {{SCAM} '07},
	title = {Finding Inputs that Reach a Target Expression},
	doi = {10.1109/SCAM.2007.30},
	abstract = {We present an automated program analysis, called Reach, to compute program inputs that cause evaluation of explicitly-marked target expressions. Reach has a range of applications including property refutation, assertion breaking, program crashing, program covering, program understanding, and the development of customised data generators. Reach is based on lazy narrowing, a symbolic evaluation strategy from functional-logic programming. We use Reach to analyse a range of programs, and find it to be a useful tool with clear performance benefits over a method based on exhaustive input generation. We also explore different methods for bounding the search space, the selective use of breadth-first search to find the first solution quickly, and techniques to avoid evaluation that is unnecessary to reach a target.},
	booktitle = {Seventh {IEEE} International Working Conference on Source Code Analysis and Manipulation, 2007. {SCAM} 2007},
	author = {Naylor, M. and Runciman, Colin},
	month = sep,
	year = {2007},
	keywords = {\_tablet, Application software, assertion breaking, automatic testing, breadth-first search, Computer crashes, Computer science, Concrete, customised data generator, explicitly-marked target expression, functional-logic programming, functional programming, lazy narrowing, logic programming, Performance analysis, Power generation, program covering, program crashing, program diagnostics, Program processors, program testing, program understanding, property refutation, Reach automated program analysis, research-exam, symbolic evaluation strategy, symbol manipulation, Target recognition},
	pages = {133--142},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XMRE98QA/articleDetails.html:text/html;Naylor and Runciman - 2007 - Finding Inputs that Reach a Target Expression.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/K9VTWG5V/Naylor and Runciman - 2007 - Finding Inputs that Reach a Target Expression.pdf:application/pdf}
}

@inproceedings{aldrich_power_2013,
	title = {The power of interoperability: why objects are inevitable},
	url = {http://portal.acm.org/citation.cfm?id=2509578.2514738&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/2509578.2514738},
	booktitle = {Onward},
	publisher = {{ACM} Request Permissions},
	author = {Aldrich, Jonathan},
	year = {2013},
	keywords = {\_tablet, adt, oop, pl},
	file = {Aldrich - 2013 - The power of interoperability why objects are ine.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/V2QMSA79/Aldrich - 2013 - The power of interoperability why objects are ine.pdf:application/pdf}
}

@inproceedings{de_moura_generalized_2009,
	title = {Generalized, efficient array decision procedures},
	doi = {10.1109/FMCAD.2009.5351142},
	abstract = {The theory of arrays is ubiquitous in the context of software and hardware verification and symbolic analysis. The basic array theory was introduced by {McCarthy} and allows to symbolically representing array updates. In this paper we present combinatory array logic, {CAL}, using a small, but powerful core of combinators, and reduce it to the theory of uninterpreted functions. {CAL} allows expressing properties that go well beyond the basic array theory. We provide a new efficient decision procedure for the base theory as well as {CAL}. The efficient procedure serves a critical role in the performance of the state-of-the-art {SMT} solver Z3 on array formulas from applications.},
	booktitle = {Formal Methods in Computer-Aided Design, 2009. {FMCAD} 2009},
	author = {de Moura, L. and Bjorner, N.},
	month = nov,
	year = {2009},
	keywords = {Arithmetic, Automata, basic array theory, combinatory array logic, Constraint theory, decision theory, Delay, efficient array decision procedure, Equations, Filters, formal logic, Formal verification, Hardware, hardware verification, Logic arrays, satisfiability modulo theory, {SMT} solver Z3, software verification, Surface-mount technology, symbolic analysis, theorem proving},
	pages = {45--52},
	file = {de Moura and Bjorner - 2009 - Generalized, efficient array decision procedures.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DZ2V2635/de Moura and Bjorner - 2009 - Generalized, efficient array decision procedures.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/KAD7N8X5/de Moura and Bjorner - 2009 - Generalized, efficient array decision procedures.html:text/html}
}

@incollection{barnett_spec_2005,
	series = {Lecture Notes in Computer Science},
	title = {The Spec\# Programming System: An Overview},
	copyright = {©2005 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-24287-1, 978-3-540-30569-9},
	shorttitle = {The Spec\# Programming System},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-30569-9_3},
	abstract = {The Spec\# programming system is a new attempt at a more cost effective way to develop and maintain high-quality software. This paper describes the goals and architecture of the Spec\# programming system, consisting of the object-oriented Spec\# programming language, the Spec\# compiler, and the Boogie static program verifier. The language includes constructs for writing specifications that capture programmer intentions about how methods and data are to be used, the compiler emits run-time checks to enforce these specifications, and the verifier can check the consistency between a program and its specifications.},
	language = {en},
	number = {3362},
	urldate = {2014-07-02},
	booktitle = {Construction and Analysis of Safe, Secure, and Interoperable Smart Devices},
	publisher = {Springer Berlin Heidelberg},
	author = {Barnett, Mike and Leino, K. Rustan M. and Schulte, Wolfram},
	editor = {Barthe, Gilles and Burdy, Lilian and Huisman, Marieke and Lanet, Jean-Louis and Muntean, Traian},
	month = jan,
	year = {2005},
	keywords = {\_tablet, Logics and Meanings of Programs, Operating Systems, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering, Special Purpose and Application-Based Systems},
	pages = {49--69},
	file = {Barnett et al. - 2005 - The Spec# Programming System An Overview.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3QTBRPGN/Barnett et al. - 2005 - The Spec# Programming System An Overview.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/FCF44XJB/978-3-540-30569-9_3.html:text/html}
}

@inproceedings{muranushi_experience_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Experience Report: Type-checking Polymorphic Units for Astrophysics Research in Haskell},
	isbn = {978-1-4503-3041-1},
	shorttitle = {Experience Report},
	url = {http://doi.acm.org/10.1145/2633357.2633362},
	doi = {10.1145/2633357.2633362},
	abstract = {Many of the bugs in scientific programs have their roots in mistreatment of physical dimensions, via erroneous expressions in the quantity calculus. Now that the type system in the Glasgow Haskell Compiler is rich enough to support type-level integers and other promoted datatypes, we can type-check the quantity calculus in Haskell. In addition to basic dimension-aware arithmetic and unit conversions, our units library features an extensible system of dimensions and units, a notion of dimensions apart from that of units, and unit polymorphism designed to describe the laws of physics. We demonstrate the utility of units by writing an astrophysics research paper. This work is free of unit concerns because every quantity expression in the paper is rigorously type-checked.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Muranushi, Takayuki and Eisenberg, Richard A.},
	year = {2014},
	keywords = {\_tablet, haskell, quantity calculus, type families, type-level computation},
	pages = {31--38},
	file = {Muranushi and Eisenberg - 2014 - Experience Report Type-checking Polymorphic Units.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9CISVFA3/Muranushi and Eisenberg - 2014 - Experience Report Type-checking Polymorphic Units.pdf:application/pdf}
}

@article{csallner_jcrasher:_2004,
	title = {{JCrasher}: an automatic robustness tester for Java},
	volume = {34},
	copyright = {Copyright © 2004 John Wiley \& Sons, Ltd.},
	issn = {1097-024X},
	shorttitle = {{JCrasher}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.602/abstract},
	doi = {10.1002/spe.602},
	abstract = {{JCrasher} is an automatic robustness testing tool for Java code. {JCrasher} examines the type information of a set of Java classes and constructs code fragments that will create instances of different types to test the behavior of public methods under random data. {JCrasher} attempts to detect bugs by causing the program under test to ‘crash’, that is, to throw an undeclared runtime exception. Although in general the random testing approach has many limitations, it also has the advantage of being completely automatic: o supervision is required except for off-line inspection of the test ases that have caused a crash. Compared to other similar commercial and research tools, {JCrasher} offers several novelties: it transitively analyzes methods, determines the size of each tested method's parameter-space and selects parameter combinations and therefore test cases at random, taking into account the time allocated for testing; it defines heuristics for determining whether a Java exception should be considered as a program bug or whether the {JCrasher} supplied inputs have violated the code's preconditions; it includes support for efficiently undoing all the state changes introduced by previous tests; it produces test files for {JUnit}, a popular Java testing tool; and it can be integrated in the Eclipse {IDE}. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {11},
	urldate = {2014-06-16},
	journal = {Software: Practice and Experience},
	author = {Csallner, Christoph and Smaragdakis, Yannis},
	month = sep,
	year = {2004},
	keywords = {\_tablet, Java, random testing, research-exam, software testing, state re-initialization, test case generation},
	pages = {1025--1050},
	file = {Csallner and Smaragdakis - 2004 - JCrasher an automatic robustness tester for Java.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/E3MZS8FV/Csallner and Smaragdakis - 2004 - JCrasher an automatic robustness tester for Java.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/79VZSQJ2/abstract.html:text/html}
}

@article{abramson_when_2011,
	title = {When Formal Systems Kill: Computer Ethics and Formal Methods},
	shorttitle = {When Formal Systems Kill},
	url = {https://www.cs.indiana.edu/~lepike/pubs/fm-ethics.pdf},
	number = {1},
	urldate = {2014-06-16},
	journal = {To appear in the {APA} Newsletter on Philosophy and Computers},
	author = {Abramson, Darren and Pike, Lee},
	year = {2011},
	keywords = {\_tablet},
	file = {Abramson and Pike - 2011 - When Formal Systems Kill Computer Ethics and Form.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/MJJ36EJD/Abramson and Pike - 2011 - When Formal Systems Kill Computer Ethics and Form.pdf:application/pdf}
}

@inproceedings{csallner_check_2005,
	address = {New York, {NY}, {USA}},
	series = {{ICSE} '05},
	title = {Check 'N' Crash: Combining Static Checking and Testing},
	isbn = {1-58113-963-2},
	shorttitle = {Check 'N' Crash},
	url = {http://doi.acm.org/10.1145/1062455.1062533},
	doi = {10.1145/1062455.1062533},
	abstract = {We present an automatic error-detection approach that combines static checking and concrete test-case generation. Our approach consists of taking the abstract error conditions inferred using theorem proving techniques by a static checker ({ESC}/Java), deriving specific error conditions using a constraint solver, and producing concrete test cases (with the {JCrasher} tool) that are executed to determine whether an error truly exists. The combined technique has advantages over both static checking and automatic testing individually. Compared to {ESC}/Java, we eliminate spurious warnings and improve the ease-of-comprehension of error reports through the production of Java counterexamples. Compared to {JCrasher}, we eliminate the blind search of the input space, thus reducing the testing time and increasing the test quality.},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the 27th International Conference on Software Engineering},
	publisher = {{ACM}},
	author = {Csallner, Christoph and Smaragdakis, Yannis},
	year = {2005},
	keywords = {\_tablet, automatic testing, dynamic analysis, extended static checking, research-exam, static analysis, test case generation, usability},
	pages = {422--431},
	file = {Csallner and Smaragdakis - 2005 - Check 'N' Crash Combining Static Checking and Tes.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3HMTQHIU/Csallner and Smaragdakis - 2005 - Check 'N' Crash Combining Static Checking and Tes.pdf:application/pdf}
}

@inproceedings{cook_understanding_2009,
	title = {On understanding data abstraction, revisited},
	url = {http://portal.acm.org/citation.cfm?id=1640089.1640133&coll=DL&dl=GUIDE&CFID=326371480&CFTOKEN=65522705},
	doi = {10.1145/1640089.1640133},
	booktitle = {{OOPSLA}},
	publisher = {{ACM} Request Permissions},
	author = {Cook, William R},
	year = {2009},
	keywords = {\_tablet, adt, oop, pl},
	file = {Cook - 2009 - On understanding data abstraction, revisited.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/6BPF3XRA/Cook - 2009 - On understanding data abstraction, revisited.pdf:application/pdf}
}

@inproceedings{oliveira_functional_2012,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '12},
	title = {Functional Programming with Structured Graphs},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364541},
	doi = {10.1145/2364527.2364541},
	abstract = {This paper presents a new functional programming model for graph structures called structured graphs. Structured graphs extend conventional algebraic datatypes with explicit definition and manipulation of cycles and/or sharing, and offer a practical and convenient way to program graphs in functional programming languages like Haskell. The representation of sharing and cycles (edges) employs recursive binders and uses an encoding inspired by parametric higher-order abstract syntax. Unlike traditional approaches based on mutable references or node/edge lists, well-formedness of the graph structure is ensured statically and reasoning can be done with standard functional programming techniques. Since the binding structure is generic, we can define many useful generic combinators for manipulating structured graphs. We give applications and show how to reason about structured graphs.},
	urldate = {2014-06-28},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Oliveira, Bruno C.d.S. and Cook, William R.},
	year = {2012},
	keywords = {\_tablet, graphs, haskell, parametric hoas},
	pages = {77--88},
	file = {Oliveira and Cook - 2012 - Functional Programming with Structured Graphs.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7IEAAMSP/Oliveira and Cook - 2012 - Functional Programming with Structured Graphs.pdf:application/pdf}
}

@inproceedings{de_vries_true_2014,
	address = {New York, {NY}, {USA}},
	series = {{WGP} '14},
	title = {True Sums of Products},
	isbn = {978-1-4503-3042-8},
	url = {http://doi.acm.org/10.1145/2633628.2633634},
	doi = {10.1145/2633628.2633634},
	abstract = {We introduce the sum-of-products ({SOP}) view for datatype-generic programming (in Haskell). While many of the libraries that are commonly in use today represent datatypes as arbitrary combinations of binary sums and products, {SOP} reflects the structure of datatypes more faithfully: each datatype is a single n-ary sum, where each component of the sum is a single n-ary product. This representation turns out to be expressible accurately in {GHC} with today's extensions. The resulting list-like structure of datatypes allows for the definition of powerful high-level traversal combinators, which in turn encourage the definition of generic functions in a compositional and concise style. A major plus of the {SOP} view is that it allows to separate function-specific metadata from the main structural representation and recombining this information later.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} Workshop on Generic Programming},
	publisher = {{ACM}},
	author = {de Vries, Edsko and Löh, Andres},
	year = {2014},
	keywords = {\_tablet, datatype-generic programming, generic views, json, lenses, metadata, sums of products, universes},
	pages = {83--94},
	file = {de Vries and Löh - 2014 - True Sums of Products.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/56UJ2W4K/de Vries and Löh - 2014 - True Sums of Products.pdf:application/pdf}
}

@article{beyer_software_2007,
	title = {The software model checker Blast},
	volume = {9},
	issn = {1433-2779, 1433-2787},
	url = {http://link.springer.com/article/10.1007/s10009-007-0044-z},
	doi = {10.1007/s10009-007-0044-z},
	abstract = {Blast is an automatic verification tool for checking temporal safety properties of C programs. Given a C program and a temporal safety property, Blast either statically proves that the program satisfies the safety property, or provides an execution path that exhibits a violation of the property (or, since the problem is undecidable, does not terminate). Blast constructs, explores, and refines abstractions of the program state space based on lazy predicate abstraction and interpolation-based predicate discovery. This paper gives an introduction to Blast and demonstrates, through two case studies, how it can be applied to program verification and test-case generation. In the first case study, we use Blast to statically prove memory safety for C programs. We use {CCured}, a type-based memory-safety analyzer, to annotate a program with run-time assertions that check for safe memory operations. Then, we use Blast to remove as many of the run-time checks as possible (by proving that these checks never fail), and to generate execution scenarios that violate the assertions for the remaining run-time checks. In our second case study, we use Blast to automatically generate test suites that guarantee full coverage with respect to a given predicate. Given a C program and a target predicate p, Blast determines the program locations q for which there exists a program execution that reaches q with p true, and automatically generates a set of test vectors that cause such executions. Our experiments show that Blast can provide automated, precise, and scalable analysis for C programs.},
	language = {en},
	number = {5-6},
	urldate = {2015-01-23},
	journal = {International Journal on Software Tools for Technology Transfer},
	author = {Beyer, Dirk and Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak},
	month = sep,
	year = {2007},
	keywords = {Memory safety, model checking, Software Engineering, Software Engineering/Programming and Operating Systems, Software specification, software verification, Test-case generation, Theory of Computation},
	pages = {505--525},
	file = {Beyer et al. - 2007 - The software model checker Blast.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GF9MUEC2/Beyer et al. - 2007 - The software model checker Blast.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/6XV7T3IJ/s10009-007-0044-z.html:text/html}
}

@inproceedings{costa_vigilante:_2005,
	address = {New York, {NY}, {USA}},
	series = {{SOSP} '05},
	title = {Vigilante: End-to-end Containment of Internet Worms},
	isbn = {1-59593-079-5},
	shorttitle = {Vigilante},
	url = {http://doi.acm.org/10.1145/1095810.1095824},
	doi = {10.1145/1095810.1095824},
	abstract = {Worm containment must be automatic because worms can spread too fast for humans to respond. Recent work has proposed network-level techniques to automate worm containment; these techniques have limitations because there is no information about the vulnerabilities exploited by worms at the network level. We propose Vigilante, a new end-to-end approach to contain worms automatically that addresses these limitations. Vigilante relies on collaborative worm detection at end hosts, but does not require hosts to trust each other. Hosts run instrumented software to detect worms and broadcast self-certifying alerts ({SCAs}) upon worm detection. {SCAs} are proofs of vulnerability that can be inexpensively verified by any vulnerable host. When hosts receive an {SCA}, they generate filters that block infection by analysing the {SCA}-guided execution of the vulnerable software. We show that Vigilante can automatically contain fast-spreading worms that exploit unknown vulnerabilities without blocking innocuous traffic.},
	urldate = {2015-01-25},
	booktitle = {Proceedings of the Twentieth {ACM} Symposium on Operating Systems Principles},
	publisher = {{ACM}},
	author = {Costa, Manuel and Crowcroft, Jon and Castro, Miguel and Rowstron, Antony and Zhou, Lidong and Zhang, Lintao and Barham, Paul},
	year = {2005},
	keywords = {control flow analysis, data flow analysis, self-certifying alerts, worm containment},
	pages = {133--147},
	file = {Costa et al. - 2005 - Vigilante End-to-end Containment of Internet Worm.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9AIRHHBH/Costa et al. - 2005 - Vigilante End-to-end Containment of Internet Worm.pdf:application/pdf}
}

@inproceedings{tomb_variably_2007,
	address = {New York, {NY}, {USA}},
	series = {{ISSTA} '07},
	title = {Variably Interprocedural Program Analysis for Runtime Error Detection},
	isbn = {978-1-59593-734-6},
	url = {http://doi.acm.org/10.1145/1273463.1273478},
	doi = {10.1145/1273463.1273478},
	abstract = {This paper describes an analysis approach based on a of static and dynamic techniques to ?nd run-time errors in Java code. It uses symbolic execution to ?nd constraints under which an error (e.g. a null pointer dereference, array out of bounds access, or assertion violation) may occur and then solves these constraints to ?nd test inputs that may expose the error. It only alerts the user to the possibility of a real error when it detects the expected exception during a program run. The analysis is customizable in two important ways. First, we can adjust how deeply to follow calls from each top-level method. Second, we can adjust the path termination tion for the symbolic execution engine to be either a bound on the path condition length or a bound on the number of times each instruction can be revisited. We evaluated the tool on a set of benchmarks from the literature as well as a number of real-world systems that range in size from a few thousand to 50,000 lines of code. The tool discovered all known errors in the benchmarks (as well as some not previously known) and reported on average 8 errors per 1000 lines of code for the industrial examples. In both cases the interprocedural call depth played little role in the error detection. That is, an intraprocedural analysis seems adequate for the class of errors we detect.},
	urldate = {2015-01-24},
	booktitle = {Proceedings of the 2007 International Symposium on Software Testing and Analysis},
	publisher = {{ACM}},
	author = {Tomb, Aaron and Brat, Guillaume and Visser, Willem},
	year = {2007},
	keywords = {can-test, defect detection, generation, symbolic execution},
	pages = {97--107},
	file = {Tomb et al. - 2007 - Variably Interprocedural Program Analysis for Runt.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/INQTJAQ9/Tomb et al. - 2007 - Variably Interprocedural Program Analysis for Runt.pdf:application/pdf}
}

@article{jhala_software_2009,
	title = {Software Model Checking},
	volume = {41},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/1592434.1592438},
	doi = {10.1145/1592434.1592438},
	abstract = {We survey recent progress in software model checking.},
	number = {4},
	urldate = {2015-01-23},
	journal = {{ACM} Comput. Surv.},
	author = {Jhala, Ranjit and Majumdar, Rupak},
	month = oct,
	year = {2009},
	keywords = {abstraction, counterexample-guided refinement, enumerative and symbolic model checking, liveness, safety, Software model checking},
	pages = {21:1--21:54},
	file = {Jhala and Majumdar - 2009 - Software Model Checking.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/FZ2GJ2VS/Jhala and Majumdar - 2009 - Software Model Checking.pdf:application/pdf}
}

@book{burnstein_practical_2003,
	title = {Practical Software Testing: A Process-Oriented Approach},
	isbn = {9780387951317},
	shorttitle = {Practical Software Testing},
	abstract = {Based on the needs of the educational community, and the software professional, this book takes a unique approach to teaching software testing. It introduces testing concepts that are managerial, technical, and process oriented, using the Testing Maturity Model ({TMM}) as a guiding framework. The {TMM} levels and goals support a structured presentation of fundamental and advanced test-related concepts to the reader. In this context, the interrelationships between theoretical, technical, and managerial concepts become more apparent. In addition, relationships between the testing process, maturity goals, and such key players as managers, testers and client groups are introduced. Topics and features:- Process/engineering-oriented text- Promotes the growth and value of software testing as a profession- Introduces both technical and managerial aspects of testing in a clear and precise style- Uses the {TMM} framework to introduce testing concepts in a systemmatic, evolutionary way to faciliate understanding- Describes the role of testing tools and measurements, and how to integrate them into the testing process Graduate students and industry professionals will benefit from the book, which is designed for a graduate course in software testing, software quality assurance, or software validation and verification Moreover, the number of universities with graduate courses that cover this material will grow, given the evoluation in software development as an engineering discipline and the creation of degree programs in software engineering.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Burnstein, Ilene},
	month = jun,
	year = {2003},
	keywords = {Computers / Information Technology, Computers / Programming / General, Computers / Programming Languages / General, Computers / Software Development \& Engineering / General, Computers / Software Development \& Engineering / Systems Analysis \& Design}
}

@article{ernst_dynamically_2001,
	title = {Dynamically discovering likely program invariants to support program evolution},
	volume = {27},
	issn = {0098-5589},
	doi = {10.1109/32.908957},
	abstract = {Explicitly stated program invariants can help programmers by identifying program properties that must be preserved when modifying code. In practice, however, these invariants are usually implicit. An alternative to expecting programmers to fully annotate code with invariants is to automatically infer likely invariants from the program itself. This research focuses on dynamic techniques for discovering invariants from execution traces. This article reports three results. First, it describes techniques for dynamically discovering invariants, along with an implementation, named Daikon, that embodies these techniques. Second, it reports on the application of Daikon to two sets of target programs. In programs from Gries's work (1981) on program derivation, the system rediscovered predefined invariants. In a C program lacking explicit invariants, the system discovered invariants that assisted a software evolution task. These experiments demonstrate that, at least for small programs, invariant inference is both accurate and useful. Third, it analyzes scalability issues, such as invariant detection runtime and accuracy, as functions of test suites and program points instrumented},
	number = {2},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Ernst, M.D. and Cockrell, J. and Griswold, William G. and Notkin, D.},
	month = feb,
	year = {2001},
	keywords = {Application software, Computer Society, Daikon, Detectors, execution traces, explicitly stated program invariants, Formal specifications, Instruments, invariant inference, likely program invariants, modifying code, Pattern analysis, program derivation, program evolution, Programming profession, program properties, reverse engineering, Runtime, scalability, small programs, software evolution, software maintenance, Testing},
	pages = {99--123},
	file = {Ernst et al. - 2001 - Dynamically discovering likely program invariants .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XHA2TMCQ/Ernst et al. - 2001 - Dynamically discovering likely program invariants .pdf:application/pdf;IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/PB4WEMGK/abs_all.html:text/html}
}

@inproceedings{zhang_toward_2014,
	address = {New York, {NY}, {USA}},
	series = {{POPL} '14},
	title = {Toward General Diagnosis of Static Errors},
	isbn = {978-1-4503-2544-8},
	url = {http://doi.acm.org/10.1145/2535838.2535870},
	doi = {10.1145/2535838.2535870},
	abstract = {We introduce a general way to locate programmer mistakes that are detected by static analyses such as type checking. The program analysis is expressed in a constraint language in which mistakes result in unsatisfiable constraints. Given an unsatisfiable system of constraints, both satisfiable and unsatisfiable constraints are analyzed, to identify the program expressions most likely to be the cause of unsatisfiability. The likelihood of different error explanations is evaluated under the assumption that the programmer's code is mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses that rely on programmer-stated assumptions, the diagnosis also identifies assumptions likely to have been omitted. The new error diagnosis approach has been implemented for two very different program analyses: type inference in {OCaml} and information flow checking in Jif. The effectiveness of the approach is evaluated using previously collected programs containing errors. The results show that when compared to existing compilers and other tools, the general technique identifies the location of programmer errors significantly more accurately.},
	urldate = {2015-01-21},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Zhang, Danfeng and Myers, Andrew C.},
	year = {2014},
	keywords = {error diagnosis, information flow, static program analysis, type inference},
	pages = {569--581},
	file = {Zhang and Myers - 2014 - Toward General Diagnosis of Static Errors.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/8WP6HDZC/Zhang and Myers - 2014 - Toward General Diagnosis of Static Errors.pdf:application/pdf}
}

@article{king_symbolic_1976,
	title = {Symbolic Execution and Program Testing},
	volume = {19},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/360248.360252},
	doi = {10.1145/360248.360252},
	number = {7},
	urldate = {2014-06-16},
	journal = {Commun. {ACM}},
	author = {King, James C.},
	month = jul,
	year = {1976},
	keywords = {\_tablet, program debugging, program proving, program testing, program verification, symbolic execution, symbolic interpretation},
	pages = {385--394},
	file = {King - 1976 - Symbolic Execution and Program Testing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/A3JJTIQJ/King - 1976 - Symbolic Execution and Program Testing.pdf:application/pdf}
}

@inproceedings{duregard_feat:_2012,
	address = {New York, {NY}, {USA}},
	series = {Haskell '12},
	title = {Feat: Functional Enumeration of Algebraic Types},
	isbn = {978-1-4503-1574-6},
	shorttitle = {Feat},
	url = {http://doi.acm.org/10.1145/2364506.2364515},
	doi = {10.1145/2364506.2364515},
	abstract = {In mathematics, an enumeration of a set S is a bijective function from (an initial segment of) the natural numbers to S. We define "functional enumerations" as efficiently computable such bijections. This paper describes a theory of functional enumeration and provides an algebra of enumerations closed under sums, products, guarded recursion and bijections. We partition each enumerated set into numbered, finite subsets. We provide a generic enumeration such that the number of each part corresponds to the size of its values (measured in the number of constructors). We implement our ideas in a Haskell library called testing-feat, and make the source code freely available. Feat provides efficient "random access" to enumerated values. The primary application is property-based testing, where it is used to define both random sampling (for example {QuickCheck} generators) and exhaustive enumeration (in the style of {SmallCheck}). We claim that functional enumeration is the best option for automatically generating test cases from large groups of mutually recursive syntax tree types. As a case study we use Feat to test the pretty-printer of the Template Haskell library (uncovering several bugs).},
	urldate = {2014-06-17},
	booktitle = {Proceedings of the 2012 Haskell Symposium},
	publisher = {{ACM}},
	author = {Duregård, Jonas and Jansson, Patrik and Wang, Meng},
	year = {2012},
	keywords = {\_tablet, enumeration, memoisation, property-based testing},
	pages = {61--72},
	file = {Durega ard et al. - 2012 - Feat Functional Enumeration of Algebraic Types.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DD8KACCX/Durega ard et al. - 2012 - Feat Functional Enumeration of Algebraic Types.pdf:application/pdf}
}

@inproceedings{wadler_how_1989,
	address = {New York, {NY}, {USA}},
	series = {{POPL} '89},
	title = {How to Make Ad-hoc Polymorphism Less Ad Hoc},
	isbn = {0-89791-294-2},
	url = {http://doi.acm.org/10.1145/75277.75283},
	doi = {10.1145/75277.75283},
	abstract = {This paper presents type classes, a new approach to ad-hoc polymorphism. Type classes permit overloading of arithmetic operators such as multiplication, and generalise the “eqtype variables” of Standard {ML}. Type classes extend the Hindley/Milner polymorphic type system, and provide a new approach to issues that arise in object-oriented programming, bounded type quantification, and abstract data types. This paper provides an informal introduction to type classes, and defines them formally by means of type inference rules.},
	urldate = {2014-07-17},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Wadler, P. and Blott, S.},
	year = {1989},
	keywords = {\_tablet},
	pages = {60--76},
	file = {Wadler and Blott - 1989 - How to Make Ad-hoc Polymorphism Less Ad Hoc.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/K5B822JU/Wadler and Blott - 1989 - How to Make Ad-hoc Polymorphism Less Ad Hoc.pdf:application/pdf}
}

@article{jackson_elements_1996,
	title = {Elements of style: analyzing a software design feature with a counterexample detector},
	volume = {22},
	issn = {0098-5589},
	shorttitle = {Elements of style},
	doi = {10.1109/32.538605},
	abstract = {Demonstrates how Nitpick, a specification checker, can be applied to the design of a style mechanism for a word processor. The design is cast, along with some expected properties, in a subset of Z. Nitpick checks a property by enumerating all possible cases within some finite bounds, displaying as a counterexample the first case for which the property fails to hold. Unlike animation or execution tools, Nitpick does not require state transitions to be expressed constructively, and unlike theorem provers, Nitpick operates completely automatically without user intervention. Using a variety of reduction mechanisms, it can cover an enormous number of cases in a reasonable time, so that subtle flaws can be rapidly detected},
	number = {7},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {Jackson, D. and Damon, C.A.},
	month = jul,
	year = {1996},
	keywords = {abstract modeling, Animation, automatic operation, case enumeration, Computer architecture, counterexample detector, Detectors, exhaustive testing, finite bounds, Formal languages, formal specification, formal specification checker, Formal specifications, Hardware, model checking, Nitpick, Process design, program testing, program verification, Protocols, reduction mechanisms, Software design, software design feature analysis, software testing, state transitions, subtle flaw detection, word processing, word processor style mechanism, Z notation, Z specification language subset},
	pages = {484--495},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/567Z26Z2/abs_all.html:text/html;Jackson and Damon - 1996 - Elements of style analyzing a software design fea.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/FC76X8MB/Jackson and Damon - 1996 - Elements of style analyzing a software design fea.pdf:application/pdf}
}

@article{adrion_validation_1982,
	title = {Validation, Verification, and Testing of Computer Software},
	volume = {14},
	issn = {0360-0300},
	url = {http://doi.acm.org/10.1145/356876.356879},
	doi = {10.1145/356876.356879},
	number = {2},
	urldate = {2015-01-27},
	journal = {{ACM} Comput. Surv.},
	author = {Adrion, W. Richards and Branstad, Martha A. and Cherniavsky, John C.},
	month = jun,
	year = {1982},
	pages = {159--192},
	file = {ACM Full Text PDF:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/KHEPJTK5/Adrion et al. - 1982 - Validation, Verification, and Testing of Computer .pdf:application/pdf}
}

@inproceedings{cadar_symbolic_2011,
	address = {New York, {NY}, {USA}},
	series = {{ICSE} '11},
	title = {Symbolic Execution for Software Testing in Practice: Preliminary Assessment},
	isbn = {978-1-4503-0445-0},
	shorttitle = {Symbolic Execution for Software Testing in Practice},
	url = {http://doi.acm.org/10.1145/1985793.1985995},
	doi = {10.1145/1985793.1985995},
	abstract = {We present results for the "Impact Project Focus Area" on the topic of symbolic execution as used in software testing. Symbolic execution is a program analysis technique introduced in the 70s that has received renewed interest in recent years, due to algorithmic advances and increased availability of computational power and constraint solving technology. We review classical symbolic execution and some modern extensions such as generalized symbolic execution and dynamic test generation. We also give a preliminary assessment of the use in academia, research labs, and industry.},
	urldate = {2015-01-22},
	booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
	publisher = {{ACM}},
	author = {Cadar, Cristian and Godefroid, Patrice and Khurshid, Sarfraz and Păsăreanu, Corina S. and Sen, Koushik and Tillmann, Nikolai and Visser, Willem},
	year = {2011},
	keywords = {dynamic test generation, generalized symbolic execution},
	pages = {1066--1071},
	file = {Cadar et al. - 2011 - Symbolic Execution for Software Testing in Practic.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/CSVNJGH3/Cadar et al. - 2011 - Symbolic Execution for Software Testing in Practic.pdf:application/pdf}
}

@inproceedings{avgerinos_aeg:_2011,
	title = {{AEG}: Automatic Exploit Generation.},
	volume = {11},
	shorttitle = {{AEG}},
	url = {http://security.ece.cmu.edu/aeg/aeg-current.pdf},
	urldate = {2015-01-25},
	booktitle = {{NDSS}},
	author = {Avgerinos, Thanassis and Cha, Sang Kil and Hao, Brent Lim Tze and Brumley, David},
	year = {2011},
	pages = {59--66},
	file = {Avgerinos et al. - 2011 - AEG Automatic Exploit Generation..pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/TX28QM3T/Avgerinos et al. - 2011 - AEG Automatic Exploit Generation..pdf:application/pdf}
}

@article{meyer_applying_1992,
	title = {Applying 'design by contract'},
	volume = {25},
	issn = {0018-9162},
	doi = {10.1109/2.161279},
	abstract = {Methodological guidelines for object-oriented software construction that improve the reliability of the resulting software systems are presented. It is shown that the object-oriented techniques rely on the theory of design by contract, which underlies the design of the Eiffel analysis, design, and programming language and of the supporting libraries, from which a number of examples are drawn. The theory of contract design and the role of assertions in that theory are discussed.{\textless}{\textgreater}},
	number = {10},
	journal = {Computer},
	author = {Meyer, B.},
	month = oct,
	year = {1992},
	keywords = {Books, Computer bugs, Contracts, design by contract, Eiffel, Guidelines, object-oriented programming, Object oriented programming, object-oriented software construction, object-oriented techniques, Pressing, programming language, Reliability theory, Robustness, Software Engineering, software libraries, software reliability, software reusability, Software systems},
	pages = {40--51},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/A634XE9C/abs_all.html:text/html}
}

@inproceedings{plociniczak_improving_2014,
	title = {Improving Human-Compiler Interaction Through Customizable Type Feedback},
	booktitle = {{SPLASH}},
	author = {Plociniczak, Hubert and Miller, Heather and Odersky, Martin},
	year = {2014},
	keywords = {\_tablet},
	file = {Plociniczak et al. - 2014 - Improving Human-Compiler Interaction Through Custo.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3PDMM7QZ/Plociniczak et al. - 2014 - Improving Human-Compiler Interaction Through Custo.pdf:application/pdf}
}

@inproceedings{diehl_generic_2014,
	address = {New York, {NY}, {USA}},
	series = {{WGP} '14},
	title = {Generic Constructors and Eliminators from Descriptions: Type Theory As a Dependently Typed Internal {DSL}},
	isbn = {978-1-4503-3042-8},
	shorttitle = {Generic Constructors and Eliminators from Descriptions},
	url = {http://doi.acm.org/10.1145/2633628.2633630},
	doi = {10.1145/2633628.2633630},
	abstract = {Dependently typed languages with an "open" type theory introduce new datatypes using an axiomatic approach. Each new datatype introduces axioms for constructing values of the datatype, and an elimination axiom (which we call the standard eliminator) for consuming such values. In a "closed" type theory a single introduction rule primitive and a single elimination rule primitive can be used for all datatypes, without adding axioms to the theory. We review a closed type theory, specified as an Agda program, that uses descriptions for datatype construction. Descriptions make datatype definitions first class values, but writing programs using such datatypes requires low-level understanding of how the datatypes are encoded in terms of descriptions. In this work we derive constructors and standard eliminators, by defining generic functions parameterized by a description. Our generic type theory constructions are defined as generic wrappers around the closed type theory primitives, which are themselves generic functions in the Agda model. Thus, we allow users to write programs in the model without understanding the details of the description-based encoding of datatypes, by using open type theory constructions as an internal domain-specific language ({IDSL}).},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} Workshop on Generic Programming},
	publisher = {{ACM}},
	author = {Diehl, Larry and Sheard, Tim},
	year = {2014},
	keywords = {\_tablet, dependent types, descriptions, eliminators, generic programming},
	pages = {3--14},
	file = {Diehl and Sheard - 2014 - Generic Constructors and Eliminators from Descript.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GRC7FHXF/Diehl and Sheard - 2014 - Generic Constructors and Eliminators from Descript.pdf:application/pdf}
}

@inproceedings{claessen_testing_2002,
	address = {New York, {NY}, {USA}},
	series = {Haskell '02},
	title = {Testing Monadic Code with {QuickCheck}},
	isbn = {1-58113-605-6},
	url = {http://doi.acm.org/10.1145/581690.581696},
	doi = {10.1145/581690.581696},
	abstract = {{QuickCheck} is a previously published random testing tool for Haskell programs. In this paper we show how to use it for testing monadic code, and in particular imperative code written using the {ST} monad. {QuickCheck} tests a program against a specification: we show that {QuickCheck}'s specification language is sufficiently powerful to represent common forms of specifications: algebraic, model-based (both functional and relational), and pre-/post-conditional. Moreover, all these forms of specification can be used directly for testing. We define a new language of monadic properties, and make a link between program testing and the notion of observational equivalence.},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the 2002 {ACM} {SIGPLAN} Workshop on Haskell},
	publisher = {{ACM}},
	author = {Claessen, Koen and Hughes, John},
	year = {2002},
	keywords = {\_tablet, research-exam, testing},
	pages = {65--77},
	file = {Claessen and Hughes - 2002 - Testing Monadic Code with QuickCheck.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7W8MAQED/Claessen and Hughes - 2002 - Testing Monadic Code with QuickCheck.pdf:application/pdf}
}

@inproceedings{banados_schwerter_theory_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {A Theory of Gradual Effect Systems},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628149},
	doi = {10.1145/2628136.2628149},
	abstract = {Effect systems have the potential to help software developers, but their practical adoption has been very limited. We conjecture that this limited adoption is due in part to the difficulty of transitioning from a system where effects are implicit and unrestricted to a system with a static effect discipline, which must settle for conservative checking in order to be decidable. To address this hindrance, we develop a theory of gradual effect checking, which makes it possible to incrementally annotate and statically check effects, while still rejecting statically inconsistent programs. We extend the generic type-and-effect framework of Marino and Millstein with a notion of unknown effects, which turns out to be significantly more subtle than unknown types in traditional gradual typing. We appeal to abstract interpretation to develop and validate the concepts of gradual effect checking. We also demonstrate how an effect system formulated in Marino and Millstein's framework can be automatically extended to support gradual checking.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Bañados Schwerter, Felipe and Garcia, Ronald and Tanter, Éric},
	year = {2014},
	keywords = {\_tablet, abstract interpretation, gradual typing, type-and-effect systems},
	pages = {283--295},
	file = {Bañados Schwerter et al. - 2014 - A Theory of Gradual Effect Systems.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3IUKUQDP/Bañados Schwerter et al. - 2014 - A Theory of Gradual Effect Systems.pdf:application/pdf}
}

@inproceedings{xi_eliminating_1998,
	address = {New York, {NY}, {USA}},
	series = {{PLDI} '98},
	title = {Eliminating Array Bound Checking Through Dependent Types},
	isbn = {0-89791-987-4},
	url = {http://doi.acm.org/10.1145/277650.277732},
	doi = {10.1145/277650.277732},
	abstract = {We present a type-based approach to eliminating array bound checking and list tag checking by conservatively extending Standard {ML} with a restricted form of dependent types. This enables the programmer to capture more invariants through types while type-checking remains decidable in theory and can still be performed efficiently in practice. We illustrate our approach through concrete examples and present the result of our preliminary experiments which support support the feasibility and effectiveness of our approach.},
	urldate = {2014-07-02},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 1998 Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Xi, Hongwei and Pfenning, Frank},
	year = {1998},
	keywords = {\_tablet},
	pages = {249--257},
	file = {Xi and Pfenning - 1998 - Eliminating Array Bound Checking Through Dependent.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/F6MVT2RV/Xi and Pfenning - 1998 - Eliminating Array Bound Checking Through Dependent.pdf:application/pdf}
}

@article{bird_automatic_1983,
	title = {Automatic generation of random self-checking test cases},
	volume = {22},
	issn = {0018-8670},
	doi = {10.1147/sj.223.0229},
	abstract = {A technique of automatically generating random software test cases is described. The nature of such test cases ensures that they will execute to completion, and their execution is predicted at the time of generation. Wherever possible the test cases are self-checking. At run-time their execution is compared with the predicted execution. Also described are implementations of the technique that have been used to test various {IBM} programs—/I language processors, sort/merge programs, and Graphical Data Display Manager alphanumeric and graphics support.},
	number = {3},
	journal = {{IBM} Systems Journal},
	author = {Bird, D. L. and Munoz, C.U.},
	year = {1983},
	keywords = {\_tablet, research-exam},
	pages = {229--245},
	file = {Bird and Munoz - 1983 - Automatic generation of random self-checking test .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BNI5W8HJ/Bird and Munoz - 1983 - Automatic generation of random self-checking test .pdf:application/pdf;IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DKVZ6RTC/articleDetails.html:text/html}
}

@inproceedings{claessen_quickcheck:_2000,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '00},
	title = {{QuickCheck}: A Lightweight Tool for Random Testing of Haskell Programs},
	isbn = {1-58113-202-6},
	shorttitle = {{QuickCheck}},
	url = {http://doi.acm.org/10.1145/351240.351266},
	doi = {10.1145/351240.351266},
	abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the Fifth {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Claessen, Koen and Hughes, John},
	year = {2000},
	keywords = {\_tablet, research-exam, testing},
	pages = {268--279},
	file = {Claessen and Hughes - 2000 - QuickCheck A Lightweight Tool for Random Testing .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/KW8HCVX2/Claessen and Hughes - 2000 - QuickCheck A Lightweight Tool for Random Testing .pdf:application/pdf}
}

@incollection{tillmann_pexwhite_2008,
	series = {Lecture Notes in Computer Science},
	title = {Pex–White Box Test Generation for .{NET}},
	copyright = {©2008 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-79123-2, 978-3-540-79124-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-79124-9_10},
	abstract = {Pex automatically produces a small test suite with high code coverage for a .{NET} program. To this end, Pex performs a systematic program analysis (using dynamic symbolic execution, similar to path-bounded model-checking) to determine test inputs for Parameterized Unit Tests. Pex learns the program behavior by monitoring execution traces. Pex uses a constraint solver to produce new test inputs which exercise different program behavior. The result is an automatically generated small test suite which often achieves high code coverage. In one case study, we applied Pex to a core component of the .{NET} runtime which had already been extensively tested over several years. Pex found errors, including a serious issue.},
	number = {4966},
	urldate = {2014-06-16},
	booktitle = {Tests and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Tillmann, Nikolai and Halleux, Jonathan de},
	editor = {Beckert, Bernhard and Hähnle, Reiner},
	month = jan,
	year = {2008},
	keywords = {\_tablet, Computer Communication Networks, Computers and Society, Logics and Meanings of Programs, research-exam, Software Engineering, System Performance and Evaluation},
	pages = {134--153},
	file = {Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5CA7FJRB/978-3-540-79124-9_10.html:text/html;Tillmann and Halleux - 2008 - Pex–White Box Test Generation for .NET.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/AQPG4ZIX/Tillmann and Halleux - 2008 - Pex–White Box Test Generation for .NET.pdf:application/pdf}
}

@inproceedings{de_moura_z3:_2008,
	address = {Berlin, Heidelberg},
	series = {{TACAS}'08/{ETAPS}'08},
	title = {Z3: An Efficient {SMT} Solver},
	isbn = {3-540-78799-2, 978-3-540-78799-0},
	shorttitle = {Z3},
	url = {http://dl.acm.org/citation.cfm?id=1792734.1792766},
	urldate = {2015-01-22},
	booktitle = {Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer-Verlag},
	author = {De Moura, Leonardo and Bjørner, Nikolaj},
	year = {2008},
	pages = {337--340},
	file = {De Moura and Bjørner - 2008 - Z3 An Efficient SMT Solver.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/I4G5W9CF/De Moura and Bjørner - 2008 - Z3 An Efficient SMT Solver.pdf:application/pdf}
}

@inproceedings{perelman_test-driven_2014,
	title = {Test-driven Synthesis},
	booktitle = {{PLDI}},
	publisher = {{ACM} Request Permissions},
	author = {Perelman, Daniel and Gulwani, Sumit and Grossman, Dan and Provost, Peter},
	year = {2014},
	keywords = {\_tablet},
	file = {Perelman et al. - 2014 - Test-driven Synthesis.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3T74GDSK/Perelman et al. - 2014 - Test-driven Synthesis.pdf:application/pdf}
}

@inproceedings{vytiniotis_halo:_2013,
	title = {{HALO}: haskell to logic through denotational semantics},
	url = {http://portal.acm.org/citation.cfm?id=2429069.2429121&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/2429069.2429121},
	booktitle = {{POPL}},
	publisher = {{ACM} Request Permissions},
	author = {Vytiniotis, Dimitrios and Peyton-Jones, Simon L and Claessen, Koen and Rosén, Dan},
	year = {2013},
	keywords = {\_tablet},
	file = {Vytiniotis et al. - 2013 - HALO haskell to logic through denotational semant.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/E58D3U6K/Vytiniotis et al. - 2013 - HALO haskell to logic through denotational semant.pdf:application/pdf}
}

@inproceedings{khoo_designing_2012,
	title = {Designing a virtual environment to evaluate multimodal sensors for assisting the visually impaired},
	volume = {2},
	url = {http://portal.acm.org/citation.cfm?id=2363956.2364049&coll=DL&dl=ACM&CFID=326685788&CFTOKEN=70440880},
	abstract = {We describe how to design a virtual environment using Microsoft Robotics Developer Studio in order to evaluate multimodal sensors for assisting visually impaired people in daily tasks such as navigation and orientation. The work focuses on the design},
	booktitle = {{ICCHP}},
	publisher = {Springer},
	author = {Khoo, Wai L and Seidel, Eric L and Zhu, Zhigang},
	year = {2012},
	file = {Khoo et al. - 2012 - Designing a virtual environment to evaluate multim.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/X6ZZ9E5Z/Khoo et al. - 2012 - Designing a virtual environment to evaluate multim.pdf:application/pdf}
}

@inproceedings{pottier_hindley-milner_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Hindley-milner Elaboration in Applicative Style: Functional Pearl},
	isbn = {978-1-4503-2873-9},
	shorttitle = {Hindley-milner Elaboration in Applicative Style},
	url = {http://doi.acm.org/10.1145/2628136.2628145},
	doi = {10.1145/2628136.2628145},
	abstract = {Type inference - the problem of determining whether a program is well-typed - is well-understood. In contrast, elaboration - the task of constructing an explicitly-typed representation of the program - seems to have received relatively little attention, even though, in a non-local type inference system, it is non-trivial. We show that the constraint-based presentation of Hindley-Milner type inference can be extended to deal with elaboration, while preserving its elegance. This involves introducing a new notion of "constraint with a value", which forms an applicative functor.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Pottier, François},
	year = {2014},
	keywords = {\_tablet, constraints, elaboration, polymorphism, type inference},
	pages = {203--212},
	file = {Pottier - 2014 - Hindley-milner Elaboration in Applicative Style F.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RPXD58MT/Pottier - 2014 - Hindley-milner Elaboration in Applicative Style F.pdf:application/pdf}
}

@incollection{smaragdakis_combining_2007,
	series = {Lecture Notes in Computer Science},
	title = {Combining Static and Dynamic Reasoning for Bug Detection},
	copyright = {©2007 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-73769-8, 978-3-540-73770-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-73770-4_1},
	abstract = {Many static and dynamic analyses have been developed to improve program quality. Several of them are well known and widely used in practice. It is not entirely clear, however, how to put these analyses together to achieve their combined benefits. This paper reports on our experiences with building a sequence of increasingly more powerful combinations of static and dynamic analyses for bug finding in the tools {JCrasher}, Check ’n’ Crash, and {DSD}-Crasher. We contrast the power and accuracy of the tools using the same example program as input to all three. At the same time, the paper discusses the philosophy behind all three tools. Specifically, we argue that trying to detect program errors (rather than to certify programs for correctness) is well integrated in the development process and a promising approach for both static and dynamic analyses. The emphasis on finding program errors influences many aspects of analysis tools, including the criteria used to evaluate them and the vocabulary of discourse.},
	language = {en},
	number = {4454},
	urldate = {2015-01-24},
	booktitle = {Tests and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Smaragdakis, Yannis and Csallner, Christoph},
	editor = {Gurevich, Yuri and Meyer, Bertrand},
	year = {2007},
	keywords = {Computer Communication Networks, Computers and Society, Logics and Meanings of Programs, Software Engineering, System Performance and Evaluation},
	pages = {1--16},
	file = {Smaragdakis and Csallner - 2007 - Combining Static and Dynamic Reasoning for Bug Det.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7IB5RWM8/Smaragdakis and Csallner - 2007 - Combining Static and Dynamic Reasoning for Bug Det.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/8MHDGD75/978-3-540-73770-4_1.html:text/html}
}

@inproceedings{chakravarty_foreign_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Foreign Inline Code: Systems Demonstration},
	isbn = {978-1-4503-3041-1},
	shorttitle = {Foreign Inline Code},
	url = {http://doi.acm.org/10.1145/2633357.2633372},
	doi = {10.1145/2633357.2633372},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Chakravarty, Manuel M.T.},
	year = {2014},
	keywords = {\_tablet, inline code, interoperability, template meta-programming},
	pages = {119--120},
	file = {Chakravarty - 2014 - Foreign Inline Code Systems Demonstration.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JNW7FZ4X/Chakravarty - 2014 - Foreign Inline Code Systems Demonstration.pdf:application/pdf}
}

@inproceedings{kawaguchi_type-based_2009,
	title = {Type-based data structure verification},
	url = {http://portal.acm.org/citation.cfm?id=1542476.1542510&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/1542476.1542510},
	booktitle = {{PLDI}},
	publisher = {{ACM} Request Permissions},
	author = {Kawaguchi, Ming and Rondon, Patrick M and Jhala, Ranjit},
	year = {2009},
	keywords = {\_tablet},
	file = {Kawaguchi et al. - 2009 - Type-based data structure verification.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/WNHT9G7C/Kawaguchi et al. - 2009 - Type-based data structure verification.pdf:application/pdf}
}

@incollection{kuncak_executing_2013,
	series = {Lecture Notes in Computer Science},
	title = {Executing Specifications Using Synthesis and Constraint Solving},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-40786-4, 978-3-642-40787-1},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-40787-1_1},
	abstract = {Specifications are key to improving software reliability as well as documenting precisely the intended behavior of software. Writing specifications is still perceived as expensive. Of course, writing implementations is at least as expensive, but is hardly questioned because there is currently no real alternative. Our goal is to give specifications a more balanced role compared to implementations, enabling the developers to compile, execute, optimize, and verify against each other mixed code fragments containing both specifications and implementations. To make specification constructs executable we combine deductive synthesis with run-time constraint solving, in both cases leveraging modern {SMT} solvers. Our tool decomposes specifications into simpler fragments using a cost-driven deductive synthesis framework. It compiles as many fragments as possible into conventional functional code; it executes the remaining fragments by invoking our constraint solver that extends an {SMT} solver to handle recursive functions. Using this approach we were able to execute constraints that describe the desired properties of integers, sets, maps and algebraic data types.},
	number = {8174},
	urldate = {2014-06-04},
	booktitle = {Runtime Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Kuncak, Viktor and Kneuss, Etienne and Suter, Philippe},
	editor = {Legay, Axel and Bensalem, Saddek},
	month = jan,
	year = {2013},
	keywords = {\_tablet, Algorithm Analysis and Problem Complexity, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {1--20},
	file = {Kuncak et al. - 2013 - Executing Specifications Using Synthesis and Const.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/28PCQ3UI/Kuncak et al. - 2013 - Executing Specifications Using Synthesis and Const.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/FCQZM2X5/978-3-642-40787-1_1.html:text/html}
}

@article{clarke_bounded_2001,
	title = {Bounded Model Checking Using Satisfiability Solving},
	volume = {19},
	issn = {0925-9856},
	url = {http://dx.doi.org/10.1023/A:1011276507260},
	doi = {10.1023/A:1011276507260},
	abstract = {The phrase model checking refers to algorithms for exploring the state space of a transition system to determine if it obeys a specification of its intended behavior. These algorithms can perform exhaustive verification in a highly automatic manner, and, thus, have attracted much interest in industry. Model checking programs are now being commercially marketed. However, model checking has been held back by the state explosion problem, which is the problem that the number of states in a system grows exponentially in the number of system components. Much research has been devoted to ameliorating this problem.In this tutorial, we first give a brief overview of the history of model checking to date, and then focus on recent techniques that combine model checking with satisfiability solving. These techniques, known as bounded model checking, do a very fast exploration of the state space, and for some types of problems seem to offer large performance improvements over previous approaches. We review experiments with bounded model checking on both public domain and industrial designs, and propose a methodology for applying the technique in industry for invariance checking. We then summarize the pros and cons of this new technology and discuss future research efforts to extend its capabilities.},
	number = {1},
	urldate = {2014-09-19},
	journal = {Form. Methods Syst. Des.},
	author = {Clarke, Edmund and Biere, Armin and Raimi, Richard and Zhu, Yunshan},
	month = jul,
	year = {2001},
	keywords = {bounded model checking, cone of influence reduction, model checking, processor verification, satisfiability},
	pages = {7--34},
	file = {Clarke et al. - 2001 - Bounded Model Checking Using Satisfiability Solvin.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/8GBWA62Q/Clarke et al. - 2001 - Bounded Model Checking Using Satisfiability Solvin.pdf:application/pdf}
}

@inproceedings{seidel_simplifying_2010,
	title = {Simplifying complex software assembly},
	isbn = {9781605588186},
	url = {http://portal.acm.org/citation.cfm?doid=1838574.1838592},
	doi = {10.1145/1838574.1838592},
	abstract = {Abstract Assembling simulation software along with the associated tools and utilities is a challenging endeavor, particularly when the components are distributed across multiple source code versioning systems. It is problematic for researchers compiling and running ...},
	booktitle = {{TG}},
	publisher = {{ACM} Press},
	author = {Seidel, Eric L. and Allen, Gabrielle and Brandt, Steven and Löffler, Frank and Schnetter, Erik},
	year = {2010},
	keywords = {\_tablet},
	pages = {1--8},
	file = {Seidel et al. - 2010 - Simplifying complex software assembly.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9M9WBBC4/Seidel et al. - 2010 - Simplifying complex software assembly.pdf:application/pdf}
}

@incollection{reich_advances_2013,
	series = {Lecture Notes in Computer Science},
	title = {Advances in Lazy {SmallCheck}},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-41581-4, 978-3-642-41582-1},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-41582-1_4},
	abstract = {A property-based testing library enables users to perform lightweight verification of software. This paper presents improvements to the Lazy {SmallCheck} property-based testing library. Users can now test properties that quantify over first-order functional values and nest universal and existential quantifiers in properties. When a property fails, Lazy {SmallCheck} now accurately expresses the partiality of the counterexample. These improvements are demonstrated through several practical examples.},
	language = {en},
	urldate = {2014-06-16},
	booktitle = {Implementation and Application of Functional Languages},
	publisher = {Springer Berlin Heidelberg},
	author = {Reich, Jason S. and Naylor, Matthew and Runciman, Colin},
	editor = {Hinze, Ralf},
	month = jan,
	year = {2013},
	keywords = {\_tablet, Automated testing, Existential quantification, Functional values, Information Systems Applications (incl. Internet), Lazy {SmallCheck}, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, research-exam, Search-based software engineering, Software Engineering},
	pages = {53--70},
	file = {Reich et al. - 2013 - Advances in Lazy SmallCheck.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XB2G4DA4/Reich et al. - 2013 - Advances in Lazy SmallCheck.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JQRHVJU2/10.html:text/html}
}

@incollection{caballero_theoretical_2001,
	series = {Lecture Notes in Computer Science},
	title = {Theoretical Foundations for the Declarative Debugging of Lazy Functional Logic Programs},
	copyright = {©2001 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-41739-2, 978-3-540-44716-0},
	url = {http://link.springer.com/chapter/10.1007/3-540-44716-4_11},
	abstract = {The aim of this paper is to provide theoretical foundations for the declarative debugging of wrong answers in lazy functional logic programming. We rely on a logical framework which formalizes both the intended meaning and the execution model of programs in a simple language which combines the expressivity of pure Prolog and a significant subset of Haskell. As novelties w.r.t. to previous related approaches, we deal with functional values both as arguments and as results of higher order functions, we obtain a completely formal specification of the debugging method, and we extend known soundness and completeness results for the debugging of wrong answers in logic programming to a substantially more difficult context. A prototype implementation of a working debugger is planned as future work.},
	language = {en},
	number = {2024},
	urldate = {2015-01-08},
	booktitle = {Functional and Logic Programming},
	publisher = {Springer Berlin Heidelberg},
	author = {Caballero, Rafael and López-Fraguas, Francisco J. and Rodrìguez-Artalejo, Mario},
	editor = {Kuchen, Herbert and Ueda, Kazunori},
	month = jan,
	year = {2001},
	keywords = {Artificial Intelligence (incl. Robotics), Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques},
	pages = {170--184},
	file = {Caballero et al. - 2001 - Theoretical Foundations for the Declarative Debugg.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/WMF8H9U8/Caballero et al. - 2001 - Theoretical Foundations for the Declarative Debugg.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3DS2I2T9/Caballero et al. - 2001 - Theoretical Foundations for the Declarative Debugg.html:text/html}
}

@inproceedings{breitner_safe_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Safe Zero-cost Coercions for Haskell},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628141},
	doi = {10.1145/2628136.2628141},
	abstract = {Generative type abstractions -- present in Haskell, {OCaml}, and other languages -- are useful concepts to help prevent programmer errors. They serve to create new types that are distinct at compile time but share a run-time representation with some base type. We present a new mechanism that allows for zero-cost conversions between generative type abstractions and their representations, even when such types are deeply nested. We prove type safety in the presence of these conversions and have implemented our work in {GHC}.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Breitner, Joachim and Eisenberg, Richard A. and Peyton Jones, Simon and Weirich, Stephanie},
	year = {2014},
	keywords = {\_tablet, coercion, haskell, newtype deriving, type class},
	pages = {189--202},
	file = {Breitner et al. - 2014 - Safe Zero-cost Coercions for Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/N3TFQTJZ/Breitner et al. - 2014 - Safe Zero-cost Coercions for Haskell.pdf:application/pdf}
}

@inproceedings{jeffrey_bugfix:_2009,
	title = {{BugFix}: A learning-based tool to assist developers in fixing bugs},
	shorttitle = {{BugFix}},
	doi = {10.1109/ICPC.2009.5090029},
	abstract = {We present a tool called {BugFix} that can assist developers in fixing program bugs. Our tool automatically analyzes the debugging situation at a statement and reports a prioritized list of relevant bug-fix suggestions that are likely to guide the developer to an appropriate fix at that statement. {BugFix} incorporates ideas from machine learning to automatically learn from new debugging situations and bug fixes over time. This enables more effective prediction of the most relevant bug-fix suggestions for newly-encountered debugging situations. The tool takes into account the static structure of a statement, the dynamic values used at that statement by both passing and failing runs, and the interesting value mapping pairs associated with that statement. We present a case study illustrating the efficacy of {BugFix} in helping developers to fix bugs.},
	booktitle = {{IEEE} 17th International Conference on Program Comprehension, 2009. {ICPC} '09},
	author = {Jeffrey, D. and Feng, Min and Gupta, N. and Gupta, R.},
	month = may,
	year = {2009},
	keywords = {{BugFix}, Computer bugs, Error correction, Failure analysis, Fault diagnosis, learning (artificial intelligence), learning-based tool, machine learning, program bugs, program debugging, Programming, Robustness, Runtime, Software debugging, Testing},
	pages = {70--79},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XFPME3UB/abs_all.html:text/html;Jeffrey et al. - 2009 - BugFix A learning-based tool to assist developers.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RCBQM8W3/Jeffrey et al. - 2009 - BugFix A learning-based tool to assist developers.pdf:application/pdf}
}

@inproceedings{adams_indentation-sensitive_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Indentation-sensitive Parsing for Parsec},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633369},
	doi = {10.1145/2633357.2633369},
	abstract = {Several popular languages including Haskell and Python use the indentation and layout of code as an essential part of their syntax. In the past, implementations of these languages used ad hoc techniques to implement layout. Recent work has shown that a simple extension to context-free grammars can replace these ad hoc techniques and provide both formal foundations and efficient parsing algorithms for indentation sensitivity. However, that previous work is limited to bottom-up, {LR}(\$k\$) parsing, and many combinator-based parsing frameworks including Parsec use top-down algorithms that are outside its scope. This paper remedies this by showing how to add indentation sensitivity to parsing frameworks like Parsec. It explores both the formal semantics of and efficient algorithms for indentation sensitivity. It derives a Parsec-based library for indentation-sensitive parsing and presents benchmarks on a real-world language that show its efficiency and practicality.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Adams, Michael D. and Ağacan, Ömer S.},
	year = {2014},
	keywords = {\_tablet, indentation sensitivity, layout, offside rule, parsec, parsing},
	pages = {121--132},
	file = {Adams and Ağacan - 2014 - Indentation-sensitive Parsing for Parsec.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/37Q3MGWG/Adams and Ağacan - 2014 - Indentation-sensitive Parsing for Parsec.pdf:application/pdf}
}

@inproceedings{tillmann_parameterized_2005,
	address = {New York, {NY}, {USA}},
	series = {{ESEC}/{FSE}-13},
	title = {Parameterized Unit Tests},
	isbn = {1-59593-014-0},
	url = {http://doi.acm.org/10.1145/1081706.1081749},
	doi = {10.1145/1081706.1081749},
	abstract = {Parameterized unit tests extend the current industry practice of using closed unit tests defined as parameterless methods. Parameterized unit tests separate two concerns: 1) They specify the external behavior of the involved methods for all test arguments. 2) Test cases can be re-obtained as traditional closed unit tests by instantiating the parameterized unit tests. Symbolic execution and constraint solving can be used to automatically choose a minimal set of inputs that exercise a parameterized unit test with respect to possible code paths of the implementation. In addition, parameterized unit tests can be used as symbolic summaries which allows symbolic execution to scale for arbitrary abstraction levels. We have developed a prototype tool which computes test cases from parameterized unit tests. We report on its first use testing parts of the .{NET} base class library.},
	urldate = {2015-01-24},
	booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Tillmann, Nikolai and Schulte, Wolfram},
	year = {2005},
	keywords = {algebraic data types, automatic test input generation, constraint solving, symbolic execution, unit testing},
	pages = {253--262},
	file = {Tillmann and Schulte - 2005 - Parameterized Unit Tests.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/PCD9MUXQ/Tillmann and Schulte - 2005 - Parameterized Unit Tests.pdf:application/pdf}
}

@inproceedings{rondon_liquid_2008,
	title = {Liquid types},
	url = {http://portal.acm.org/citation.cfm?id=1375581.1375602&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/1375581.1375602},
	booktitle = {{PLDI}},
	publisher = {{ACM} Request Permissions},
	author = {Rondon, Patrick M and Kawaguchi, Ming and Jhala, Ranjit},
	year = {2008},
	keywords = {\_tablet},
	file = {Rondon et al. - 2008 - Liquid types.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3W92932W/Rondon et al. - 2008 - Liquid types.pdf:application/pdf}
}

@inproceedings{krustev_software_1999,
	title = {Software test generation using refinement types},
	doi = {10.1109/ASE.1999.802321},
	abstract = {A novel approach for automatic software test generation is presented, which combines ideas from structural and functional testing as well as formal verification methods. It involves as an intermediate step, the construction of graphs and refinement types, which can be regarded as an automatically constructed semi-specification and used for formal verification. The technique is illustrated using a simple functional language, with algorithms for assigning refinement types and for test generation. Some desirable theoretical properties of the approach are briefly considered. It is also compared informally to other well-known as well as new techniques for automatic test generation},
	booktitle = {Automated Software Engineering, 1999. 14th {IEEE} International Conference on.},
	author = {Krustev, D.N.},
	month = oct,
	year = {1999},
	keywords = {automatically constructed semi-specification, automatic programming, automatic software test generation, automatic testing, Formal specifications, Formal verification, formal verification methods, functional languages, functional testing, Informatics, intermediate step, Logic testing, program testing, program verification, Read only memory, refinement types, simple functional language, Software quality, software testing, Tree graphs, type theory},
	pages = {279--282},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/VXPBBG7V/abs_all.html:text/html;Krustev - 1999 - Software test generation using refinement types.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GMQ63HER/Krustev - 1999 - Software test generation using refinement types.pdf:application/pdf}
}

@inproceedings{claessen_generating_2014,
	series = {{FLOPS} '14},
	title = {Generating Constrained Random Data with Uniform Distribution},
	url = {http://publications.lib.chalmers.se/publication/195847},
	abstract = {We present a technique for automatically deriving test data generators from a predicate expressed as a Boolean function. The distribution of these generators is uniform over values of a given size. To make the generation efficient we rely on laziness of the predicate, allowing us to prune the space of values quickly. In contrast, implementing test data generators by hand is labour intensive and error prone. Moreover, handwritten generators often have an unpredictable distribution of values, risking that some values are arbitrarily underrepresented. We also present a variation of the technique where the distribution is skewed in a limited and predictable way, potentially increasing the performance. Experimental evaluation of the techniques shows that the uniform derived generators are much easier to define than hand-written ones, and their performance, while lower, is adequate for some realistic applications.},
	language = {English},
	urldate = {2014-06-04},
	author = {Claessen, Koen and Duregård, Jonas and Palka, Michal H.},
	year = {2014},
	keywords = {\_tablet, artiklar, konferensbidrag, Publikationer, rapporter},
	file = {Claessen et al. - 2014 - Generating Constrained Random Data with Uniform Di.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/K4W5479P/Claessen et al. - 2014 - Generating Constrained Random Data with Uniform Di.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/8FH3GDRQ/195847.html:text/html}
}

@inproceedings{kawaguchi_deterministic_2012,
	title = {Deterministic parallelism via liquid effects},
	url = {http://portal.acm.org/citation.cfm?id=2254064.2254071&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/2254064.2254071},
	booktitle = {{PLDI}},
	publisher = {{ACM} Request Permissions},
	author = {Kawaguchi, Ming and Rondon, Patrick M and Bakst, Alexander and Jhala, Ranjit},
	year = {2012},
	keywords = {\_tablet},
	file = {Kawaguchi et al. - 2012 - Deterministic parallelism via liquid effects.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3MRNUSCM/Kawaguchi et al. - 2012 - Deterministic parallelism via liquid effects.pdf:application/pdf}
}

@inproceedings{tobin-hochstadt_higher-order_2012,
	title = {Higher-order symbolic execution via contracts},
	url = {http://portal.acm.org/citation.cfm?id=2384616.2384655&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/2384616.2384655},
	booktitle = {{OOPSLA}},
	publisher = {{ACM} Request Permissions},
	author = {Tobin-Hochstadt, Sam and Van Horn, David},
	year = {2012},
	keywords = {\_tablet},
	file = {Tobin-Hochstadt and Van Horn - 2012 - Higher-order symbolic execution via contracts.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/TFNBPJZ7/Tobin-Hochstadt and Van Horn - 2012 - Higher-order symbolic execution via contracts.pdf:application/pdf}
}

@inproceedings{beyer_generating_2004,
	address = {Washington, {DC}, {USA}},
	series = {{ICSE} '04},
	title = {Generating Tests from Counterexamples},
	isbn = {0-7695-2163-0},
	url = {http://dl.acm.org/citation.cfm?id=998675.999437},
	abstract = {We have extended the software model checker {BLAST} toautomatically generate test suites that guarantee full coveragewith respect to a given predicate. More precisely, givena C program and a target predicate p, {BLAST} determinesthe set L of program locations which program execution canreach with p true, and automatically generates a set of testvectors that exhibit the truth of p at all locations in L. Wehave used {BLAST} to generate test suites and to detect deadcode in C programs with up to 30 K lines of code. The analysisand test-vector generation is fully automatic (no userintervention) and exact (no false positives).},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the 26th International Conference on Software Engineering},
	publisher = {{IEEE} Computer Society},
	author = {Beyer, Dirk and Chlipala, Adam J. and Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak},
	year = {2004},
	keywords = {\_tablet, research-exam},
	pages = {326--335},
	file = {Beyer et al. - 2004 - Generating Tests from Counterexamples.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5DUI3HJK/Beyer et al. - 2004 - Generating Tests from Counterexamples.pdf:application/pdf}
}

@inproceedings{petricek_coeffects:_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Coeffects: A Calculus of Context-dependent Computation},
	isbn = {978-1-4503-2873-9},
	shorttitle = {Coeffects},
	url = {http://doi.acm.org/10.1145/2628136.2628160},
	doi = {10.1145/2628136.2628160},
	abstract = {The notion of context in functional languages no longer refers just to variables in scope. Context can capture additional properties of variables (usage patterns in linear logics; caching requirements in dataflow languages) as well as additional resources or properties of the execution environment (rebindable resources; platform version in a cross-platform application). The recently introduced notion of coeffects captures the latter, whole-context properties, but it failed to capture fine-grained per-variable properties. We remedy this by developing a generalized coeffect system with annotations indexed by a coeffect shape. By instantiating a concrete shape, our system captures previously studied flat (whole-context) coeffects, but also structural (per-variable) coeffects, making coeffect analyses more useful. We show that the structural system enjoys desirable syntactic properties and we give a categorical semantics using extended notions of indexed comonad. The examples presented in this paper are based on analysis of established language features (liveness, linear logics, dataflow, dynamic scoping) and we argue that such context-aware properties will also be useful for future development of languages for increasingly heterogeneous and distributed platforms.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Petricek, Tomas and Orchard, Dominic and Mycroft, Alan},
	year = {2014},
	keywords = {\_tablet, coeffects, context, indexed comonads, types},
	pages = {123--135},
	file = {Petricek et al. - 2014 - Coeffects A Calculus of Context-dependent Computa.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/EXSB8S8M/Petricek et al. - 2014 - Coeffects A Calculus of Context-dependent Computa.pdf:application/pdf}
}

@article{parnas_criteria_1972,
	title = {On the criteria to be used in decomposing systems into modules},
	volume = {15},
	url = {http://portal.acm.org/citation.cfm?doid=361598.361623},
	doi = {10.1145/361598.361623},
	abstract = {This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a “modularization” is dependent upon the criteria used in dividing the ...},
	number = {12},
	journal = {Communications of the {ACM}},
	author = {Parnas, David L},
	year = {1972},
	keywords = {\_tablet},
	pages = {1053--1058},
	file = {Parnas - 1972 - On the criteria to be used in decomposing systems .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DFWXNU9V/Parnas - 1972 - On the criteria to be used in decomposing systems .pdf:application/pdf}
}

@book{pope_buddha_1998,
	title = {Buddha – A Declarative Debugger for Haskell},
	abstract = {Due to their reliance on the execution order of programs, traditional debugging techniques are not well suited to locating the source of logical errors in programs written in lazy functional languages. We describe the implementation of a declarative debugger for the programming language Haskell, which assists the location of logical errors based on the declarative semantics of program definitions. The implementation is based on the Hugs interpreter, and both solidifies previous work in the field and extends it to incorporate features typical of many modern lazy functional languages.},
	author = {Pope, Bernard},
	year = {1998},
	file = {Citeseer - Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7GK3XD8D/Pope - 1998 - Buddha – A Declarative Debugger for Haskell.html:text/html;Pope - 1998 - Buddha – A Declarative Debugger for Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/2XJPXC56/Pope - 1998 - Buddha – A Declarative Debugger for Haskell.pdf:application/pdf}
}

@inproceedings{raychev_refactoring_2013,
	title = {Refactoring with synthesis},
	volume = {48},
	isbn = {9781450323741},
	url = {http://dl.acm.org/citation.cfm?doid=2509136.2509544},
	doi = {10.1145/2509136.2509544},
	abstract = {Refactoring has become an integral part of modern software development, with wide support in popular integrated development environments ({IDEs}). Modern {IDEs} provide a fixed set of supported refactorings, listed in a refactoring menu. But with {IDEs} supporting},
	booktitle = {{OOPSLA}},
	publisher = {{ACM} Request Permissions},
	author = {Raychev, Veselin and Schäfer, Max and Sridharan, Manu and Vechev, Martin},
	year = {2013},
	keywords = {\_tablet},
	pages = {339--354},
	file = {Raychev et al. - 2013 - Refactoring with synthesis.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BG34ENIH/Raychev et al. - 2013 - Refactoring with synthesis.pdf:application/pdf}
}

@incollection{griswold_coping_2001,
	series = {Lecture Notes in Computer Science},
	title = {Coping with Crosscutting Software Changes Using Information Transparency},
	copyright = {©2001 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-42618-9, 978-3-540-45429-8},
	url = {http://link.springer.com/chapter/10.1007/3-540-45429-2_17},
	abstract = {Designers are often unsuccessful in designing for change using traditional modularity techniques. A complementary modularity technique called information transparency can improve a designer’s ability to simplify changes by exposing the interdependence of dispersed program elements that must be changed together for correctness. Information transparency represents modules via similarity and architecture, rather than locality and abstraction.With these, a programmer can create locality with a software tool, easing change in much the same way as traditional modularity. When combined with information hiding, then, more complex module structures can be represented. Information transparency techniques include naming conventions, formatting style, and ordering of code in a file. Transparency can be increased by better matching tool capabilities and programming style. We discuss applications of information transparency and introduce design principles for software designers and tool designers.},
	language = {en},
	number = {2192},
	urldate = {2014-12-21},
	booktitle = {Metalevel Architectures and Separation of Crosscutting Concerns},
	publisher = {Springer Berlin Heidelberg},
	author = {Griswold, William G.},
	editor = {Yonezawa, Akinori and Matsuoka, Satoshi},
	month = jan,
	year = {2001},
	keywords = {Computer Communication Networks, design, implementation techniques, Logics and Meanings of Programs, Modularity, Operating Systems, Programming Languages, Compilers, Interpreters, programming methodology, Programming Techniques, Software Engineering, software evolution, software maintenance},
	pages = {250--265},
	file = {Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XCCFAV4S/Griswold et al. - 2001 - Coping with Crosscutting Software Changes Using In.html:text/html}
}

@inproceedings{pacheco_feedback-directed_2007,
	title = {Feedback-Directed Random Test Generation},
	doi = {10.1109/ICSE.2007.37},
	abstract = {We present a technique that improves random test generation by incorporating feedback obtained from executing test inputs as they are created. Our technique builds inputs incrementally by randomly selecting a method call to apply and finding arguments from among previously-constructed inputs. As soon as an input is built, it is executed and checked against a set of contracts and filters. The result of the execution determines whether the input is redundant, illegal, contract-violating, or useful for generating more inputs. The technique outputs a test suite consisting of unit tests for the classes under test. Passing tests can be used to ensure that code contracts are preserved across program changes; failing tests (that violate one or more contract) point to potential errors that should be corrected. Our experimental results indicate that feedback-directed random test generation can outperform systematic and undirected random test generation, in terms of coverage and error detection. On four small but nontrivial data structures (used previously in the literature), our technique achieves higher or equal block and predicate coverage than model checking (with and without abstraction) and undirected random generation. On 14 large, widely-used libraries (comprising 780KLOC), feedback-directed random test generation finds many previously-unknown errors, not found by either model checking or undirected random generation.},
	booktitle = {29th International Conference on Software Engineering, 2007. {ICSE} 2007},
	author = {Pacheco, C. and Lahiri, S.K. and Ernst, M.D. and Ball, T.},
	month = may,
	year = {2007},
	keywords = {Contracts, Error correction codes, error detection, failing tests, Feedback, feedback-directed random test generation, Filters, Law, Legal factors, Object oriented modeling, Open source software, passing tests, program testing, software testing, System testing},
	pages = {75--84},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5AMA6QCU/abs_all.html:text/html;Pacheco et al. - 2007 - Feedback-Directed Random Test Generation.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5B9A7FW2/Pacheco et al. - 2007 - Feedback-Directed Random Test Generation.pdf:application/pdf}
}

@inproceedings{kaki_relational_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {A Relational Framework for Higher-order Shape Analysis},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628159},
	doi = {10.1145/2628136.2628159},
	abstract = {We propose the integration of a relational specification framework within a dependent type system capable of verifying complex invariants over the shapes of algebraic datatypes. Our approach is based on the observation that structural properties of such datatypes can often be naturally expressed as inductively-defined relations over the recursive structure evident in their definitions. By interpreting constructor applications (abstractly) in a relational domain, we can define expressive relational abstractions for a variety of complex data structures, whose structural and shape invariants can be automatically verified. Our specification language also allows for definitions of parametricrelations for polymorphic data types that enable highly composable specifications and naturally generalizes to higher-order polymorphic functions. We describe an algorithm that translates relational specifications into a decidable fragment of first-order logic that can be efficiently discharged by an {SMT} solver. We have implemented these ideas in a type checker called {CATALYST} that is incorporated within the {MLton} {SML} compiler. Experimental results and case studies indicate that our verification strategy is both practical and effective.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Kaki, Gowtham and Jagannathan, Suresh},
	year = {2014},
	keywords = {\_tablet, decidability, dependent types, inductive relations, parametric relations, relational specifications, standard ml},
	pages = {311--324},
	file = {Kaki and Jagannathan - 2014 - A Relational Framework for Higher-order Shape Anal.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JBG7ME2A/Kaki and Jagannathan - 2014 - A Relational Framework for Higher-order Shape Anal.pdf:application/pdf;Kaki and Jagannathan - 2014 - A Relational Framework for Higher-order Shape Anal.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/Q3S6NTIA/Kaki and Jagannathan - 2014 - A Relational Framework for Higher-order Shape Anal.pdf:application/pdf}
}

@book{beizer_black-box_1995,
	address = {New York, {NY}, {USA}},
	title = {Black-box Testing: Techniques for Functional Testing of Software and Systems},
	isbn = {0-471-12094-4},
	shorttitle = {Black-box Testing},
	publisher = {John Wiley \&amp; Sons, Inc.},
	author = {Beizer, Boris},
	year = {1995}
}

@inproceedings{st-amour_experience_2013,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '13},
	title = {Experience Report: Applying Random Testing to a Base Type Environment},
	isbn = {978-1-4503-2326-0},
	shorttitle = {Experience Report},
	url = {http://doi.acm.org/10.1145/2500365.2500616},
	doi = {10.1145/2500365.2500616},
	abstract = {As programmers, programming in typed languages increases our confidence in the correctness of our programs. As type system designers, soundness proofs increase our confidence in the correctness of our type systems. There is more to typed languages than their typing rules, however. To be usable, a typed language needs to provide a well-furnished standard library and to specify types for its exports. As software artifacts, these base type environments can rival typecheckers in complexity. Our experience with the Typed Racket base environment---which accounts for 31\% of the code in the Typed Racket implementation---teaches us that writing type environments can be just as error-prone as writing typecheckers. We report on our experience over the past two years of using random testing to increase our confidence in the correctness of the Typed Racket base environment.},
	urldate = {2014-08-19},
	booktitle = {Proceedings of the 18th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {St-Amour, Vincent and Toronto, Neil},
	year = {2013},
	keywords = {\_tablet, numeric towers, random testing, type environments},
	pages = {351--356},
	file = {St-Amour and Toronto - 2013 - Experience Report Applying Random Testing to a Ba.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/R8C6BGAA/St-Amour and Toronto - 2013 - Experience Report Applying Random Testing to a Ba.pdf:application/pdf}
}

@article{csallner_dsd-crasher:_2008,
	title = {{DSD}-Crasher: A Hybrid Analysis Tool for Bug Finding},
	volume = {17},
	issn = {1049-331X},
	shorttitle = {{DSD}-Crasher},
	url = {http://doi.acm.org/10.1145/1348250.1348254},
	doi = {10.1145/1348250.1348254},
	abstract = {{DSD}-Crasher is a bug finding tool that follows a three-step approach to program analysis: D. Capture the program's intended execution behavior with dynamic invariant detection. The derived invariants exclude many unwanted values from the program's input domain. S. Statically analyze the program within the restricted input domain to explore many paths. D. Automatically generate test cases that focus on reproducing the predictions of the static analysis. Thereby confirmed results are feasible. This three-step approach yields benefits compared to past two-step combinations in the literature. In our evaluation with third-party applications, we demonstrate higher precision over tools that lack a dynamic step and higher efficiency over tools that lack a static step.},
	number = {2},
	urldate = {2015-01-24},
	journal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Csallner, Christoph and Smaragdakis, Yannis and Xie, Tao},
	month = may,
	year = {2008},
	keywords = {automatic testing, bug finding, dynamic analysis, dynamic invariant detection, extended static checking, false positives, static analysis, test case generation, usability},
	pages = {8:1--8:37},
	file = {Csallner et al. - 2008 - DSD-Crasher A Hybrid Analysis Tool for Bug Findin.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/VM436B8S/Csallner et al. - 2008 - DSD-Crasher A Hybrid Analysis Tool for Bug Findin.pdf:application/pdf}
}

@inproceedings{orchard_embedding_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Embedding Effect Systems in Haskell},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633368},
	doi = {10.1145/2633357.2633368},
	abstract = {Monads are now an everyday tool in functional programming for abstracting and delimiting effects. The link between monads and effect systems is well-known, but in their typical use, monads provide a much more coarse-grained view of effects. Effect systems capture fine-grained information about the effects, but monads provide only a binary view: effectful or pure. Recent theoretical work has unified fine-grained effect systems with monads using a monad-like structure indexed by a monoid of effect annotations (called parametric effect monads). This aligns the power of monads with the power of effect systems. This paper leverages recent advances in Haskell's type system (as provided by {GHC}) to embed this approach in Haskell, providing user-programmable effect systems. We explore a number of practical examples that make Haskell even better and safer for effectful programming. Along the way, we relate the examples to other concepts, such as Haskell's implicit parameters and coeffects.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Orchard, Dominic and Petricek, Tomas},
	year = {2014},
	keywords = {\_tablet, effect systems, parametric effect monads, type systems},
	pages = {13--24},
	file = {Orchard and Petricek - 2014 - Embedding Effect Systems in Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RPVGF4XD/Orchard and Petricek - 2014 - Embedding Effect Systems in Haskell.pdf:application/pdf}
}

@incollection{claessen_testing_2003,
	series = {Lecture Notes in Computer Science},
	title = {Testing and Tracing Lazy Functional Programs Using {QuickCheck} and Hat},
	copyright = {©2003 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-40132-2, 978-3-540-44833-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-44833-4_3},
	abstract = {It is a very undesirable situation that today’s software often contains errors. One motivation for using a functional programming language is that it is more difficult (or even impossible) to make low-level mistakes, and it is easier to reason about programs. But even the most advanced functional programmers are not infallible; they misunderstand the properties of their own programs, or those of others, and so commit errors.},
	language = {en},
	number = {2638},
	urldate = {2015-01-08},
	booktitle = {Advanced Functional Programming},
	publisher = {Springer Berlin Heidelberg},
	author = {Claessen, Koen and Runciman, Colin and Chitil, Olaf and Hughes, John and Wallace, Malcolm},
	editor = {Jeuring, Johan and Jones, Simon L. Peyton},
	month = jan,
	year = {2003},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {59--99},
	file = {Claessen et al. - 2003 - Testing and Tracing Lazy Functional Programs Using.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/QBUTKGPF/Claessen et al. - 2003 - Testing and Tracing Lazy Functional Programs Using.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/UJZA3MQF/Claessen et al. - 2003 - Testing and Tracing Lazy Functional Programs Using.html:text/html}
}

@inproceedings{dinges_targeted_2014,
	address = {New York, {NY}, {USA}},
	series = {{ASE} '14},
	title = {Targeted Test Input Generation Using Symbolic-concrete Backward Execution},
	isbn = {978-1-4503-3013-8},
	url = {http://doi.acm.org/10.1145/2642937.2642951},
	doi = {10.1145/2642937.2642951},
	abstract = {Knowing inputs that cover a specific branch or statement in a program is useful for debugging and regression testing. Symbolic backward execution ({SBE}) is a natural approach to find such targeted inputs. However, {SBE} struggles with complicated arithmetic, external method calls, and data-dependent loops that occur in many real-world programs. We propose symcretic execution, a novel combination of {SBE} and concrete forward execution that can efficiently find targeted inputs despite these challenges. An evaluation of our approach on a range of test cases shows that symcretic execution finds inputs in more cases than concolic testing tools while exploring fewer path segments. Integration of our approach will allow test generation tools to fill coverage gaps and static bug detectors to verify candidate bugs with concrete test cases.},
	urldate = {2015-01-22},
	booktitle = {Proceedings of the 29th {ACM}/{IEEE} International Conference on Automated Software Engineering},
	publisher = {{ACM}},
	author = {Dinges, Peter and Agha, Gul},
	year = {2014},
	keywords = {backward execution, concolic, goal-directed, symcretic},
	pages = {31--36},
	file = {Dinges and Agha - 2014 - Targeted Test Input Generation Using Symbolic-conc.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/SZ7CUCPX/Dinges and Agha - 2014 - Targeted Test Input Generation Using Symbolic-conc.pdf:application/pdf}
}

@incollection{cadar_execution_2005,
	series = {Lecture Notes in Computer Science},
	title = {Execution Generated Test Cases: How to Make Systems Code Crash Itself},
	copyright = {©2005 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-28195-5, 978-3-540-31899-6},
	shorttitle = {Execution Generated Test Cases},
	url = {http://link.springer.com/chapter/10.1007/11537328_2},
	abstract = {This paper presents a technique that uses code to automatically generate its own test cases at run time by using a combination of symbolic and concrete (i.e regular) execution The input values to a program (or software component) provide the standard interface of any testing framework with the program it is testing and generating input values that will explore all the “interesting” behavior in the tested program remains an important open problem in software testing research. Our approach works by turning the problem on its head: we lazily generate from within the program itself the input values to the program (and values derived from input values) as needed. We applied the technique to real code and found numerous corner case errors ranging from simple memory overflows and infinite loops to subtle issues in the interpretation of language standards.},
	language = {en},
	number = {3639},
	urldate = {2015-01-23},
	booktitle = {Model Checking Software},
	publisher = {Springer Berlin Heidelberg},
	author = {Cadar, Cristian and Engler, Dawson},
	editor = {Godefroid, Patrice},
	year = {2005},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Software Engineering},
	pages = {2--23},
	file = {Cadar and Engler - 2005 - Execution Generated Test Cases How to Make System.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5SNNI9U6/Cadar and Engler - 2005 - Execution Generated Test Cases How to Make System.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9V96TJXV/10.html:text/html}
}

@inproceedings{magalhaes_generic_2010,
	address = {New York, {NY}, {USA}},
	series = {Haskell '10},
	title = {A Generic Deriving Mechanism for Haskell},
	isbn = {978-1-4503-0252-4},
	url = {http://doi.acm.org/10.1145/1863523.1863529},
	doi = {10.1145/1863523.1863529},
	abstract = {Haskell's deriving mechanism supports the automatic generation of instances for a number of functions. The Haskell 98 Report only specifies how to generate instances for the Eq, Ord, Enum, Bounded, Show, and Read classes. The description of how to generate instances is largely informal. The generation of instances imposes restrictions on the shape of datatypes, depending on the particular class to derive. As a consequence, the portability of instances across different compilers is not guaranteed. We propose a new approach to Haskell's deriving mechanism, which allows users to specify how to derive arbitrary class instances using standard datatype-generic programming techniques. Generic functions, including the methods from six standard Haskell 98 derivable classes, can be specified entirely within Haskell 98 plus multi-parameter type classes, making them lightweight and portable. We can also express Functor, Typeable, and many other derivable classes with our technique. We implemented our deriving mechanism together with many new derivable classes in the Utrecht Haskell Compiler.},
	urldate = {2014-06-23},
	booktitle = {Proceedings of the Third {ACM} Haskell Symposium on Haskell},
	publisher = {{ACM}},
	author = {Magalhães, José Pedro and Dijkstra, Atze and Jeuring, Johan and Löh, Andres},
	year = {2010},
	keywords = {\_tablet, datatype-generic programming, haskell, type classes},
	pages = {37--48},
	file = {Magalhães et al. - 2010 - A Generic Deriving Mechanism for Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GH7SHGTW/Magalhães et al. - 2010 - A Generic Deriving Mechanism for Haskell.pdf:application/pdf}
}

@inproceedings{xie_symstra:_2005,
	title = {Symstra: A Framework for Generating Object-Oriented Unit Tests Using Symbolic Execution},
	volume = {3440},
	isbn = {978-3-540-31980-1},
	url = {http://link.springer.com/10.1007/978-3-540-31980-1_24},
	doi = {10.1007/978-3-540-31980-1_24},
	abstract = {Object-oriented unit tests consist of sequences of method invocations. Behavior of an invocation depends on the method’s arguments and the state of the receiver at the beginning of the invocation. Correspondingly, generating unit tests involves two tasks: generating method sequences that build relevant receiver-object states and generating relevant method arguments. This paper proposes Symstra, a framework that achieves both test generation tasks using symbolic execution of method sequences with symbolic arguments. The paper defines symbolic states of object-oriented programs and novel comparisons of states. Given a set of methods from the class under test and a bound on the length of sequences, Symstra systematically explores the object-state space of the class and prunes this exploration based on the state comparisons. Experimental results show that Symstra generates unit tests that achieve higher branch coverage faster than the existing test-generation techniques based on concrete method arguments.},
	booktitle = {{TACAS}},
	publisher = {Springer Berlin Heidelberg},
	author = {Xie, Tao and Marinov, Darko and Schulte, Wolfram and Notkin, David},
	year = {2005},
	keywords = {\_tablet},
	pages = {365--381},
	file = {Xie et al. - 2005 - Symstra A Framework for Generating Object-Oriente.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/A6R98U7G/Xie et al. - 2005 - Symstra A Framework for Generating Object-Oriente.pdf:application/pdf}
}

@inproceedings{runciman_smallcheck_2008,
	address = {New York, {NY}, {USA}},
	series = {Haskell '08},
	title = {Smallcheck and Lazy Smallcheck: Automatic Exhaustive Testing for Small Values},
	isbn = {978-1-60558-064-7},
	shorttitle = {Smallcheck and Lazy Smallcheck},
	url = {http://doi.acm.org/10.1145/1411286.1411292},
	doi = {10.1145/1411286.1411292},
	abstract = {This paper describes two Haskell libraries for property-based testing. Following the lead of {QuickCheck}, these testing libraries {SmallCheck} and Lazy {SmallCheck} also use type-based generators to obtain test-sets of finite values for which properties are checked, and report any counter-examples found. But instead of using a sample of randomly generated values they test properties for all values up to some limiting depth, progressively increasing this limit. The paper explains the design and implementation of both libraries and evaluates them in comparison with each other and with {QuickCheck}.},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the First {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Runciman, Colin and Naylor, Matthew and Lindblad, Fredrik},
	year = {2008},
	keywords = {\_tablet, embedded language, exhaustive search, lazy evaluation, property-based testing, research-exam, testing, type classes},
	pages = {37--48},
	file = {Runciman et al. - 2008 - Smallcheck and Lazy Smallcheck Automatic Exhausti.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GCUX24DT/Runciman et al. - 2008 - Smallcheck and Lazy Smallcheck Automatic Exhausti.pdf:application/pdf}
}

@inproceedings{ekblad_seamless_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {A Seamless, Client-centric Programming Model for Type Safe Web Applications},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633367},
	doi = {10.1145/2633357.2633367},
	abstract = {We propose a new programming model for web applications which is (1) seamless; one program and one language is used to produce code for both client and server, (2) client-centric; the programmer takes the viewpoint of the client that runs code on the server rather than the other way around, (3) functional and type-safe, and (4) portable; everything is implemented as a Haskell library that implicitly takes care of all networking code. Our aim is to improve the painful and error-prone experience of today's standard development methods, in which clients and servers are coded in different languages and communicate with each other using ad-hoc protocols. We present the design of our library called Haste.App, an example web application that uses it, and discuss the implementation and the compiler technology on which it depends.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Ekblad, Anton and Claessen, Koen},
	year = {2014},
	keywords = {\_tablet, distributed systems, network communication, web applications},
	pages = {79--89},
	file = {Ekblad and Claessen - 2014 - A Seamless, Client-centric Programming Model for T.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7E6GG782/Ekblad and Claessen - 2014 - A Seamless, Client-centric Programming Model for T.pdf:application/pdf}
}

@inproceedings{ishii_tangible_1997,
	title = {Tangible bits: towards seamless interfaces between people, bits and atoms},
	url = {http://portal.acm.org/citation.cfm?id=258549.258715&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/258549.258715},
	booktitle = {{CHI}},
	publisher = {{ACM} Request Permissions},
	author = {Ishii, Hiroshi and Ullmer, Brygg},
	year = {1997},
	keywords = {\_tablet},
	file = {Ishii and Ullmer - 1997 - Tangible bits towards seamless interfaces between.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/IJP83THG/Ishii and Ullmer - 1997 - Tangible bits towards seamless interfaces between.pdf:application/pdf}
}

@inproceedings{eisenberg_promoting_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Promoting Functions to Type Families in Haskell},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633361},
	doi = {10.1145/2633357.2633361},
	abstract = {Haskell, as implemented in the Glasgow Haskell Compiler ({GHC}), is enriched with many extensions that support type-level programming, such as promoted datatypes, kind polymorphism, and type families. Yet, the expressiveness of the type-level language remains limited. It is missing many features present at the term level, including case expressions, anonymous functions, partially-applied functions, and let expressions. In this paper, we present an algorithm - with a proof of correctness - to encode these term-level constructs at the type level. Our approach is automated and capable of promoting a wide array of functions to type families. We also highlight and discuss those term-level features that are not promotable. In so doing, we offer a critique on {GHC}'s existing type system, showing what it is already capable of and where it may want improvement. We believe that delineating the mismatch between {GHC}'s term level and its type level is a key step toward supporting dependently typed programming.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Eisenberg, Richard A. and Stolarek, Jan},
	year = {2014},
	keywords = {\_tablet, defunctionalization, haskell, type-level programming},
	pages = {95--106},
	file = {Eisenberg and Stolarek - 2014 - Promoting Functions to Type Families in Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/C5MADSHT/Eisenberg and Stolarek - 2014 - Promoting Functions to Type Families in Haskell.pdf:application/pdf}
}

@article{_learning_????,
	title = {Learning Dependent Types from Tests},
	keywords = {\_tablet},
	file = {Learning Dependent Types from Tests.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3Z6KE9XV/Learning Dependent Types from Tests.pdf:application/pdf}
}

@inproceedings{godefroid_dart:_2005,
	address = {New York, {NY}, {USA}},
	series = {{PLDI} '05},
	title = {{DART}: Directed Automated Random Testing},
	isbn = {1-59593-056-6},
	shorttitle = {{DART}},
	url = {http://doi.acm.org/10.1145/1065010.1065036},
	doi = {10.1145/1065010.1065036},
	abstract = {We present a new tool, named {DART}, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or {DART} for short. The main strength of {DART} is thus that testing can be performed completely automatically on any program that compiles -- there is no need to write any test driver or harness code. During testing, {DART} detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
	urldate = {2014-05-22},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
	year = {2005},
	keywords = {\_tablet, automated test generation, interfaces, program verification, random testing, research-exam, software testing},
	pages = {213--223},
	file = {Godefroid et al. - 2005 - DART Directed Automated Random Testing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JSME6TB7/Godefroid et al. - 2005 - DART Directed Automated Random Testing.pdf:application/pdf}
}

@inproceedings{marlow_there_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {There is No Fork: An Abstraction for Efficient, Concurrent, and Concise Data Access},
	isbn = {978-1-4503-2873-9},
	shorttitle = {There is No Fork},
	url = {http://doi.acm.org/10.1145/2628136.2628144},
	doi = {10.1145/2628136.2628144},
	abstract = {We describe a new programming idiom for concurrency, based on Applicative Functors, where concurrency is implicit in the Applicative {\textless}*{\textgreater} operator. The result is that concurrent programs can be written in a natural applicative style, and they retain a high degree of clarity and modularity while executing with maximal concurrency. This idiom is particularly useful for programming against external data sources, where the application code is written without the use of explicit concurrency constructs, while the implementation is able to batch together multiple requests for data from the same source, and fetch data from multiple sources concurrently. Our abstraction uses a cache to ensure that multiple requests for the same data return the same result, which frees the programmer from having to arrange to fetch data only once, which in turn leads to greater modularity. While it is generally applicable, our technique was designed with a particular application in mind: an internal service at Facebook that identifies particular types of content and takes actions based on it. Our application has a large body of business logic that fetches data from several different external sources. The framework described in this paper enables the business logic to execute efficiently by automatically fetching data concurrently; we present some preliminary results.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Marlow, Simon and Brandy, Louis and Coens, Jonathan and Purdy, Jon},
	year = {2014},
	keywords = {\_tablet, applicative, concurrency, data-fetching, distributed, haskell, monad},
	pages = {325--337},
	file = {Marlow et al. - 2014 - There is No Fork An Abstraction for Efficient, Co.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/MUKUBNIB/Marlow et al. - 2014 - There is No Fork An Abstraction for Efficient, Co.pdf:application/pdf}
}

@inproceedings{grabmayer_maximal_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Maximal Sharing in the Lambda Calculus with Letrec},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628148},
	doi = {10.1145/2628136.2628148},
	abstract = {Increasing sharing in programs is desirable to compactify the code, and to avoid duplication of reduction work at run-time, thereby speeding up execution. We show how a maximal degree of sharing can be obtained for programs expressed as terms in the lambda calculus with letrec. We introduce a notion of 'maximal compactness' for λletrec-terms among all terms with the same infinite unfolding. Instead of defined purely syntactically, this notion is based on a graph semantics. λletrec-terms are interpreted as first-order term graphs so that unfolding equivalence between terms is preserved and reflected through bisimilarity of the term graph interpretations. Compactness of the term graphs can then be compared via functional bisimulation. We describe practical and efficient methods for the following two problems: transforming a λletrec-term into a maximally compact form; and deciding whether two λletrec-terms are unfolding-equivalent. The transformation of a λletrec-terms L into maximally compact form L0 proceeds in three steps: (i) translate L into its term graph G = [[L]] ; (ii) compute the maximally shared form of G as its bisimulation collapse G0 ; (iii) read back a λletrec-term L0 from the term graph G0 with the property [[L0]] = G0. Then L0 represents a maximally shared term graph, and it has the same unfolding as L. The procedure for deciding whether two given λletrec-terms L1 and L2 are unfolding-equivalent computes their term graph interpretations [[L1]] and [[L2]], and checks whether these are bisimilar. For illustration, we also provide a readily usable implementation.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Grabmayer, Clemens and Rochel, Jan},
	year = {2014},
	keywords = {\_tablet, higher-order term graphs, lambda calculus with letrec, maximal sharing, subterm sharing, unfolding semantics},
	pages = {67--80},
	file = {Grabmayer and Rochel - 2014 - Maximal Sharing in the Lambda Calculus with Letrec.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/C3USV6XT/Grabmayer and Rochel - 2014 - Maximal Sharing in the Lambda Calculus with Letrec.pdf:application/pdf}
}

@inproceedings{wadler_comprehending_1990,
	address = {New York, {NY}, {USA}},
	series = {{LFP} '90},
	title = {Comprehending Monads},
	isbn = {0-89791-368-X},
	url = {http://doi.acm.org/10.1145/91556.91592},
	doi = {10.1145/91556.91592},
	abstract = {Category theorists invented monads in the 1960's to concisely express certain aspects of universal algebra. Functional programmers invented list comprehensions in the 1970's to concisely express certain programs involving lists. This paper shows how list comprehensions may be generalised to an arbitrary monad, and how the resulting programming feature can concisely express in a pure functional language some programs that manipulate state, handle exceptions, parse text, or invoke continuations. A new solution to the old problem of destructive array update is also presented. No knowledge of category theory is assumed.},
	urldate = {2014-07-17},
	booktitle = {Proceedings of the 1990 {ACM} Conference on {LISP} and Functional Programming},
	publisher = {{ACM}},
	author = {Wadler, Philip},
	year = {1990},
	keywords = {\_tablet},
	pages = {61--78},
	file = {Wadler - 1990 - Comprehending Monads.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/SC6J57QX/Wadler - 1990 - Comprehending Monads.pdf:application/pdf}
}

@article{jackson_alloy:_2002,
	title = {Alloy: A Lightweight Object Modelling Notation},
	volume = {11},
	issn = {1049-331X},
	shorttitle = {Alloy},
	url = {http://doi.acm.org/10.1145/505145.505149},
	doi = {10.1145/505145.505149},
	abstract = {Alloy is a little language for describing structural properties. It offers a declaration syntax compatible with graphical object models, and a set-based formula syntax powerful enough to express complex constraints and yet amenable to a fully automatic semantic analysis. Its meaning is given by translation to an even smaller (formally defined) kernel. This paper presents the language in its entirety, and explains its motivation, contributions and deficiencies.},
	number = {2},
	urldate = {2015-01-27},
	journal = {{ACM} Trans. Softw. Eng. Methodol.},
	author = {Jackson, Daniel},
	month = apr,
	year = {2002},
	keywords = {first-order logic, object models, Z specification language},
	pages = {256--290}
}

@inproceedings{kuncak_relational_2005,
	address = {New York, {NY}, {USA}},
	series = {{ESEC}/{FSE}-13},
	title = {Relational Analysis of Algebraic Datatypes},
	isbn = {1-59593-014-0},
	url = {http://doi.acm.org/10.1145/1081706.1081740},
	doi = {10.1145/1081706.1081740},
	abstract = {We present a technique that enables the use of finite model finding to check the satisfiability of certain formulas whose intended models are infinite. Such formulas arise when using the language of sets and relations to reason about structured values such as algebraic datatypes. The key idea of our technique is to identify a natural syntactic class of formulas in relational logic for which reasoning about infinite structures can be reduced to reasoning about finite structures. As a result, when a formula belongs to this class, we can use existing finite model finding tools to check whether the formula holds in the desired infinite model.},
	urldate = {2014-09-09},
	booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Kuncak, Viktor and Jackson, Daniel},
	year = {2005},
	keywords = {algebraic datatypes, constraint solving, model checking, model finding, transitive closure logic},
	pages = {207--216},
	file = {Kuncak and Jackson - 2005 - Relational Analysis of Algebraic Datatypes.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7QN33F6J/Kuncak and Jackson - 2005 - Relational Analysis of Algebraic Datatypes.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/X3EEAZH7/citation.html:text/html}
}

@inproceedings{flanagan_extended_2002,
	address = {New York, {NY}, {USA}},
	series = {{PLDI} '02},
	title = {Extended Static Checking for Java},
	isbn = {1-58113-463-0},
	url = {http://doi.acm.org/10.1145/512529.512558},
	doi = {10.1145/512529.512558},
	abstract = {Software development and maintenance are costly endeavors. The cost can be reduced if more software defects are detected earlier in the development cycle. This paper introduces the Extended Static Checker for Java ({ESC}/Java), an experimental compile-time program checker that finds common programming errors. The checker is powered by verification-condition generation and automatic theorem-proving techniques. It provides programmers with a simple annotation language with which programmer design decisions can be expressed formally. {ESC}/Java examines the annotated software and warns of inconsistencies between the design decisions recorded in the annotations and the actual code, and also warns of potential runtime errors in the code. This paper gives an overview of the checker architecture and annotation language and describes our experience applying the checker to tens of thousands of lines of Java programs.},
	urldate = {2014-07-01},
	booktitle = {Proceedings of the {ACM} {SIGPLAN} 2002 Conference on Programming Language Design and Implementation},
	publisher = {{ACM}},
	author = {Flanagan, Cormac and Leino, K. Rustan M. and Lillibridge, Mark and Nelson, Greg and Saxe, James B. and Stata, Raymie},
	year = {2002},
	keywords = {\_tablet, checking, compile-time, program},
	pages = {234--245},
	file = {Flanagan et al. - 2002 - Extended Static Checking for Java.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/PPV4AIWQ/Flanagan et al. - 2002 - Extended Static Checking for Java.pdf:application/pdf}
}

@inproceedings{jackson_alcoa:_2000,
	title = {Alcoa: the Alloy constraint analyzer},
	shorttitle = {Alcoa},
	doi = {10.1109/ICSE.2000.870482},
	abstract = {Alcoa is a tool for analyzing object models. It has a range of uses. At one end, it can act as a support tool for object model diagrams, checking for consistency of multiplicities and generating sample snapshots. At the other end, it embodies a lightweight formal method in which subtle properties of behaviour can be investigated. Alcoa's input language, Alloy, is a new notation based on Z. Its development was motivated by the need for a notation that is more closely tailored to object models (in the style of {UML}), and more amenable to automatic analysis. Like Z, Alloy supports the description of systems whose state involves complex relational structure. State and behavioural properties are described declaratively, by conjoining constraints. This makes it possible to develop and analyze a model incrementally, with Alcoa investigating the consequences of whatever constraints are given. Alcoa works by translating constraints to boolean formulas, and then applying state-of-the-art {SAT} solvers. It can analyze billions of states in seconds},
	booktitle = {Proceedings of the 2000 International Conference on Software Engineering, 2000},
	author = {Jackson, D. and Schechter, I. and Shlyakhter, I.},
	year = {2000},
	keywords = {Alcoa, Alloy constraint analyzer, boolean formula, Boolean functions, complex relational structure, Computer science, constraint handling, constraint satisfaction, data structures, diagrams, File systems, formal method, formal specification, Formal specifications, Laboratories, Logic, notation, object model diagrams, object models, object-oriented programming, Permission, program compiler, program compilers, relational algebra, relational logic, Risk analysis, {SAT} solvers, software analysis, software tools, specification languages, Topology, {UML}, Unified modeling language, Z language},
	pages = {730--733},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/Q2ZZ9655/abs_all.html:text/html}
}

@inproceedings{cadar_exe:_2006,
	address = {New York, {NY}, {USA}},
	series = {{CCS} '06},
	title = {{EXE}: Automatically Generating Inputs of Death},
	isbn = {1-59593-518-5},
	shorttitle = {{EXE}},
	url = {http://doi.acm.org/10.1145/1180405.1180445},
	doi = {10.1145/1180405.1180445},
	abstract = {This paper presents {EXE}, an effective bug-finding tool that automatically generates inputs that crash real code. Instead of running code on manually or randomly constructed input, {EXE} runs it on symbolic input initially allowed to be "anything." As checked code runs, {EXE} tracks the constraints on each symbolic (i.e., input-derived) memory location. If a statement uses a symbolic value, {EXE} does not run it, but instead adds it as an input-constraint; all other statements run as usual. If code conditionally checks a symbolic expression, {EXE} forks execution, constraining the expression to be true on the true branch and false on the other. Because {EXE} reasons about all possible values on a path, it has much more power than a traditional runtime tool: (1) it can force execution down any feasible program path and (2) at dangerous operations (e.g., a pointer dereference), it detects if the current path constraints allow any value that causes a bug.When a path terminates or hits a bug, {EXE} automatically generates a test case by solving the current path constraints to find concrete values using its own co-designed constraint solver, {STP}. Because {EXE}'s constraints have no approximations, feeding this concrete input to an uninstrumented version of the checked code will cause it to follow the same path and hit the same bug (assuming deterministic code).{EXE} works well on real code, finding bugs along with inputs that trigger them in: the {BSD} and Linux packet filter implementations, the udhcpd {DHCP} server, the pcre regular expression library, and three Linux file systems.},
	urldate = {2015-01-22},
	booktitle = {Proceedings of the 13th {ACM} Conference on Computer and Communications Security},
	publisher = {{ACM}},
	author = {Cadar, Cristian and Ganesh, Vijay and Pawlowski, Peter M. and Dill, David L. and Engler, Dawson R.},
	year = {2006},
	keywords = {attack generation, bug finding, constraint solving, dynamic analysis, symbolic execution, test case generation},
	pages = {322--335},
	file = {Cadar et al. - 2006 - EXE Automatically Generating Inputs of Death.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/M938IQV7/Cadar et al. - 2006 - EXE Automatically Generating Inputs of Death.pdf:application/pdf}
}

@inproceedings{chugh_nested_2012,
	title = {Nested refinements: a logic for duck typing},
	url = {http://portal.acm.org/citation.cfm?id=2103656.2103686&coll=DL&dl=ACM&CFID=445811551&CFTOKEN=90926960},
	doi = {10.1145/2103656.2103686},
	booktitle = {{POPL}},
	publisher = {{ACM} Request Permissions},
	author = {Chugh, Ravi and Rondon, Patrick M and Jhala, Ranjit},
	year = {2012},
	keywords = {\_tablet},
	file = {Chugh et al. - 2012 - Nested refinements a logic for duck typing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/TIM6DWBJ/Chugh et al. - 2012 - Nested refinements a logic for duck typing.pdf:application/pdf}
}

@inproceedings{khalek_testera:_2011,
	title = {Testera: A tool for testing java programs using alloy specifications},
	shorttitle = {Testera},
	url = {http://dl.acm.org/citation.cfm?id=2190145},
	urldate = {2014-09-09},
	booktitle = {Proceedings of the 2011 26th {IEEE}/{ACM} international conference on automated software engineering},
	publisher = {{IEEE} Computer Society},
	author = {Khalek, Shadi Abdul and Yang, Guowei and Zhang, Lingming and Marinov, Darko and Khurshid, Sarfraz},
	year = {2011},
	keywords = {\_tablet},
	pages = {608--611},
	file = {Khalek et al. - 2011 - Testera A tool for testing java programs using al.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/X8QVUCAC/Khalek et al. - 2011 - Testera A tool for testing java programs using al.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/E6HTKT3S/citation.html:text/html}
}

@inproceedings{gill_type-safe_2009,
	address = {New York, {NY}, {USA}},
	series = {Haskell '09},
	title = {Type-safe Observable Sharing in Haskell},
	isbn = {978-1-60558-508-6},
	url = {http://doi.acm.org/10.1145/1596638.1596653},
	doi = {10.1145/1596638.1596653},
	abstract = {Haskell is a great language for writing and supporting embedded Domain Specific Languages ({DSLs}). Some form of observable sharing is often a critical capability for allowing so-called deep {DSLs} to be compiled and processed. In this paper, we describe and explore uses of an {IO} function for reification which allows direct observation of sharing.},
	urldate = {2014-06-28},
	booktitle = {Proceedings of the 2Nd {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Gill, Andy},
	year = {2009},
	keywords = {\_tablet, {DSL} compilation, observable sharing},
	pages = {117--128},
	file = {Gill - 2009 - Type-safe Observable Sharing in Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BQUAXGPG/Gill - 2009 - Type-safe Observable Sharing in Haskell.pdf:application/pdf}
}

@incollection{chitil_freja_2001,
	series = {Lecture Notes in Computer Science},
	title = {Freja, Hat and Hood - A Comparative Evaluation of Three Systems for Tracing and Debugging Lazy Functional Programs},
	copyright = {©2001 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-41919-8, 978-3-540-45361-1},
	url = {http://link.springer.com/chapter/10.1007/3-540-45361-X_11},
	abstract = {In this paper we compare three systems for tracing and debugging Haskell programs: Freja, Hat and Hood. We evaluate their usefulness in practice by applying them to a number of moderately complex programs in which errors had deliberately been introduced. We identify the strengths and weaknesses of each system and then form ideas on how the systems can be improved further.},
	language = {en},
	number = {2011},
	urldate = {2015-01-08},
	booktitle = {Implementation of Functional Languages},
	publisher = {Springer Berlin Heidelberg},
	author = {Chitil, Olaf and Runciman, Colin and Wallace, Malcolm},
	editor = {Mohnen, Markus and Koopman, Pieter},
	month = jan,
	year = {2001},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques},
	pages = {176--193},
	file = {Chitil et al. - 2001 - Freja, Hat and Hood - A Comparative Evaluation of .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JCHQMRBA/Chitil et al. - 2001 - Freja, Hat and Hood - A Comparative Evaluation of .pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/TPMJTW3Q/Chitil et al. - 2001 - Freja, Hat and Hood - A Comparative Evaluation of .html:text/html}
}

@inproceedings{sen_cute:_2005,
	address = {New York, {NY}, {USA}},
	series = {{ESEC}/{FSE}-13},
	title = {{CUTE}: A Concolic Unit Testing Engine for C},
	isbn = {1-59593-014-0},
	shorttitle = {{CUTE}},
	url = {http://doi.acm.org/10.1145/1081706.1081750},
	doi = {10.1145/1081706.1081750},
	abstract = {In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, {CUTE}, a tool implementing the method is described together with the results of applying {CUTE} to real-world examples of C code.},
	urldate = {2014-05-22},
	booktitle = {Proceedings of the 10th European Software Engineering Conference Held Jointly with 13th {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Sen, Koushik and Marinov, Darko and Agha, Gul},
	year = {2005},
	keywords = {\_tablet, concolic testing, data structure testing, explicit path model-checking, random testing, research-exam, testing C programs, unit testing},
	pages = {263--272},
	file = {Sen et al. - 2005 - CUTE A Concolic Unit Testing Engine for C.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/A9J4SKWC/Sen et al. - 2005 - CUTE A Concolic Unit Testing Engine for C.pdf:application/pdf}
}

@techreport{majumdar_latest_2007,
	title = {{LATEST} : Lazy Dynamic Test Input Generation},
	url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2007/EECS-2007-36.html},
	abstract = {We present lazy expansion, a new algorithm for scalable test input generation using directed concolic execution. Lazy expansion is an instantiation of the counterexample-guided refinement paradigm from static software verification in the context of testing. Our algorithm works in two phases. It first explores, using concolic execution, an abstraction of the function under test by replacing each called function with an unconstrained input. Second, for each (possibly spurious) trace generated by this abstraction, it attempts to expand the trace to a concretely realizable execution by recursively expanding the called functions and finding concrete executions in the called functions that can be stitched together with the original trace to form a complete program execution. Thus, it reduces the burden of symbolic reasoning about interprocedural paths to reasoning about intraprocedural paths (in the exploration phase), together with a localized and constrained search through functions (in the concretization phase). Lazy expansion is particularly effective in testing functions that make more-or-less independent calls to lower level library functions (that have already been unit tested), by only exploring relevant paths in the function under test. We have implemented our algorithm on top of the {CUTE} concolic execution tool for C and applied it to testing parser code in small compilers. In preliminary experiments, our tool, called {LATEST}, outperformed {CUTE} by an order of magnitude in terms of the time taken to generate inputs, and in contrast to {CUTE}, produced many syntactically valid input strings which exercised interesting paths through the compiler (rather than only the parser error handling code).},
	number = {{UCB}/{EECS}-2007-36},
	institution = {{EECS} Department, University of California, Berkeley},
	author = {Majumdar, Rupak and Sen, Koushik},
	month = mar,
	year = {2007},
	file = {Majumdar and Sen - 2007 - LATEST  Lazy Dynamic Test Input Generation.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/G4SZKE4S/Majumdar and Sen - 2007 - LATEST  Lazy Dynamic Test Input Generation.pdf:application/pdf}
}

@inproceedings{lattner_llvm:_2004,
	title = {{LLVM}: a compilation framework for lifelong program analysis transformation},
	shorttitle = {{LLVM}},
	doi = {10.1109/CGO.2004.1281665},
	abstract = {We describe {LLVM} (low level virtual machine), a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. {LLVM} defines a common, low-level code representation in static single assignment ({SSA}) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The {LLVM} compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the {LLVM} representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits {LLVM} provides for several challenging compiler problems.},
	booktitle = {International Symposium on Code Generation and Optimization, 2004. {CGO} 2004},
	author = {Lattner, C. and Adve, V.},
	month = mar,
	year = {2004},
	keywords = {Algorithm design and analysis, Application software, Arithmetic, C language, code representation, compiler framework, compiler performance, compiler transformations, exception handling, High level languages, Information analysis, language-independent type-system, low level virtual machine, optimising compilers, Performance analysis, program analysis, program diagnostics, Program processors, program transformation, Runtime, Software safety, static single assignment form, typed address arithmetic, virtual machines, Virtual machining},
	pages = {75--86},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/4JIHTBUF/abs_all.html:text/html;Lattner and Adve - 2004 - LLVM a compilation framework for lifelong program.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7TKE4IKJ/Lattner and Adve - 2004 - LLVM a compilation framework for lifelong program.pdf:application/pdf}
}

@inproceedings{bahr_composing_2014,
	address = {New York, {NY}, {USA}},
	series = {{WGP} '14},
	title = {Composing and Decomposing Data Types: A Closed Type Families Implementation of Data Types \&\#224; La Carte},
	isbn = {978-1-4503-3042-8},
	shorttitle = {Composing and Decomposing Data Types},
	url = {http://doi.acm.org/10.1145/2633628.2633635},
	doi = {10.1145/2633628.2633635},
	abstract = {Wouter Swierstra's data types à la carte is a technique to modularise data type definitions in Haskell. We give an alternative implementation of data types à la carte that offers more flexibility in composing and decomposing data types. To achieve this, we refine the subtyping constraint, which is at the centre of data types à la carte. On the one hand this refinement is more general, allowing subtypings that intuitively should hold but were not derivable beforehand. This aspect of our implementation removes previous restrictions on how data types can be combined. On the other hand our refinement is more restrictive, disallowing subtypings that lead to more than one possible injection and should therefore be considered programming errors. Furthermore, from this refined subtyping constraint we derive a new constraint to express type isomorphism. We show how this isomorphism constraint allows us to decompose data types and to define extensible functions on data types in an ad hoc manner. The implementation makes essential use of closed type families in Haskell. The use of closed type families instead of type classes comes with a set of trade-offs, which we review in detail. Finally, we show that our technique can be used for other similar problem domains.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} Workshop on Generic Programming},
	publisher = {{ACM}},
	author = {Bahr, Patrick},
	year = {2014},
	keywords = {\_tablet, closed type families, expression problem, Modularity, two-level types},
	pages = {71--82},
	file = {Bahr - 2014 - Composing and Decomposing Data Types A Closed Typ.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RSGZABJT/Bahr - 2014 - Composing and Decomposing Data Types A Closed Typ.pdf:application/pdf}
}

@inproceedings{klein_randomized_2009,
	title = {Randomized testing in {PLT} Redex},
	url = {http://users.eecs.northwestern.edu/~robby/pubs/papers/scheme2009-kf.pdf},
	urldate = {2014-08-19},
	booktitle = {{ACM} {SIGPLAN} Workshop on Scheme and Functional Programming},
	author = {Klein, Casey and Findler, Robert Bruce},
	year = {2009},
	keywords = {\_tablet},
	file = {Klein and Findler - 2009 - Randomized testing in PLT Redex.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/WIW2TZBA/Klein and Findler - 2009 - Randomized testing in PLT Redex.pdf:application/pdf}
}

@article{leavens_preliminary_2006,
	title = {Preliminary Design of {JML}: A Behavioral Interface Specification Language for Java},
	volume = {31},
	issn = {0163-5948},
	shorttitle = {Preliminary Design of {JML}},
	url = {http://doi.acm.org/10.1145/1127878.1127884},
	doi = {10.1145/1127878.1127884},
	abstract = {{JML} is a behavioral interface specification language tailored to Java({TM}). Besides pre- and postconditions, it also allows assertions to be intermixed with Java code; these aid verification and debugging. {JML} is designed to be used by working software engineers; to do this it follows Eiffel in using Java expressions in assertions. {JML} combines this idea from Eiffel with the model-based approach to specifications, typified by {VDM} and Larch, which results in greater expressiveness. Other expressiveness advantages over Eiffel include quantifiers, specification-only variables, and frame conditions.This paper discusses the goals of {JML}, the overall approach, and describes the basic features of the language through examples. It is intended for readers who have some familiarity with both Java and behavioral specification using pre- and postconditions.},
	number = {3},
	urldate = {2015-01-24},
	journal = {{SIGSOFT} Softw. Eng. Notes},
	author = {Leavens, Gary T. and Baker, Albert L. and Ruby, Clyde},
	month = may,
	year = {2006},
	pages = {1--38},
	file = {Leavens et al. - 2006 - Preliminary Design of JML A Behavioral Interface .pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BAW2G29E/Leavens et al. - 2006 - Preliminary Design of JML A Behavioral Interface .pdf:application/pdf}
}

@inproceedings{chitil_practical_2012,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '12},
	title = {Practical Typed Lazy Contracts},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364539},
	doi = {10.1145/2364527.2364539},
	abstract = {Until now there has been no support for specifying and enforcing contracts within a lazy functional program. That is a shame, because contracts consist of pre- and post-conditions for functions that go beyond the standard static types. This paper presents the design and implementation of a small, easy-to-use, purely functional contract library for Haskell, which, when a contract is violated, also provides more useful information than the classical blaming of one contract partner. From now on lazy functional languages can profit from the assurances in the development of correct programs that contracts provide.},
	urldate = {2015-01-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Chitil, Olaf},
	year = {2012},
	keywords = {haskell, lazy, library, purely functional},
	pages = {67--76},
	file = {Chitil - 2012 - Practical Typed Lazy Contracts.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/5JI2MTWV/Chitil - 2012 - Practical Typed Lazy Contracts.pdf:application/pdf}
}

@inproceedings{cadar_klee:_2008,
	address = {Berkeley, {CA}, {USA}},
	series = {{OSDI}'08},
	title = {{KLEE}: Unassisted and Automatic Generation of High-coverage Tests for Complex Systems Programs},
	shorttitle = {{KLEE}},
	url = {http://dl.acm.org/citation.cfm?id=1855741.1855756},
	abstract = {We present a new symbolic execution tool, {KLEE}, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used {KLEE} to thoroughly check all 89 stand-alone programs in the {GNU} {COREUTILS} utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. {KLEE}-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the {BUSYBOX} embedded system suite, results were even better, including 100\% coverage on 31 of them. We also used {KLEE} as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in {COREUTILS} that had been missed for over 15 years. Finally, we used {KLEE} to crosscheck purportedly identical {BUSYBOX} and {COREUTILS} utilities, finding functional correctness errors and a myriad of inconsistencies.},
	urldate = {2015-01-23},
	booktitle = {Proceedings of the 8th {USENIX} Conference on Operating Systems Design and Implementation},
	publisher = {{USENIX} Association},
	author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
	year = {2008},
	pages = {209--224},
	file = {Cadar et al. - 2008 - KLEE Unassisted and Automatic Generation of High-.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/4DAJT3BF/Cadar et al. - 2008 - KLEE Unassisted and Automatic Generation of High-.pdf:application/pdf;Citeseer - Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/EZXISK7A/summary.html:text/html}
}

@incollection{hughes_quickcheck_2006,
	series = {Lecture Notes in Computer Science},
	title = {{QuickCheck} Testing for Fun and Profit},
	copyright = {©2007 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-69608-7, 978-3-540-69611-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-69611-7_1},
	abstract = {One of the nice things about purely functional languages is that functions often satisfy simple properties, and enjoy simple algebraic relationships. Indeed, if the functions of an {API} satisfy elegant laws, that in itself is a sign of a good design—the laws not only indicate conceptual simplicity, but are useful in practice for simplifying programs that use the {API}, by equational reasoning or otherwise.},
	language = {en},
	number = {4354},
	urldate = {2015-01-27},
	booktitle = {Practical Aspects of Declarative Languages},
	publisher = {Springer Berlin Heidelberg},
	author = {Hughes, John},
	editor = {Hanus, Michael},
	year = {2006},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {1--32},
	file = {Full Text PDF:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/GSFQS4D3/Hughes - 2006 - QuickCheck Testing for Fun and Profit.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DNT3253X/978-3-540-69611-7_1.html:text/html}
}

@inproceedings{jackson_automating_2000,
	address = {New York, {NY}, {USA}},
	series = {{SIGSOFT} '00/{FSE}-8},
	title = {Automating First-order Relational Logic},
	isbn = {1-58113-205-0},
	url = {http://doi.acm.org/10.1145/355045.355063},
	doi = {10.1145/355045.355063},
	abstract = {An automatic analysis method for first-order logic with sets and relations is described. A first-order formula is translated to a quantifier-free boolean formula, which has a model when the original formula has a model within a given scope (that is, involving no more than some finite number of atoms). Because the satisfiable formulas that occur in practice tend to have small models, a small scope usually suffices and the analysis is efficient.
The paper presents a simple logic and gives a compositional translation scheme. It also reports briefly on experience using the Alloy Analyzer, a tool that implements the scheme.},
	urldate = {2015-01-27},
	booktitle = {Proceedings of the 8th {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering: Twenty-first Century Applications},
	publisher = {{ACM}},
	author = {Jackson, Daniel},
	year = {2000},
	keywords = {automatic analysis, constraint solvers, first-order logic, model finding, object models, relational logic, {SAT} solvers, Z specification},
	pages = {130--139},
	file = {ACM Full Text PDF:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3N4JHJDQ/Jackson - 2000 - Automating First-order Relational Logic.pdf:application/pdf}
}

@inproceedings{yang_automatically_2006,
	title = {Automatically generating malicious disks using symbolic execution},
	doi = {10.1109/SP.2006.7},
	abstract = {Many current systems allow data produced by potentially malicious sources to be mounted as a file system. File system code must check this data for dangerous values or invariant violations before using it. Because file system code typically runs inside the operating system kernel, even a single unchecked value can crash the machine or lead to an exploit. Unfortunately, validating file system images is complex: they form {DAGs} with complex dependency relationships across massive amounts of data bound together with intricate, undocumented assumptions. This paper shows how to automatically find bugs in such code using symbolic execution. Rather than running the code on manually-constructed concrete input, we instead run it on symbolic input that is initially allowed to be "anything." As the code runs, it observes (tests) this input and thus constrains its possible values. We generate test cases by solving these constraints for concrete values. The approach works well in practice: we checked the disk mounting code of three widely-used Linux file systems: ext2, ext3, and {JFS} and found bugs in all of them where malicious data could either cause a kernel panic or form the basis of a buffer overflow attack},
	booktitle = {2006 {IEEE} Symposium on Security and Privacy},
	author = {Yang, Junfeng and Sar, Can and Twohey, P. and Cadar, C. and Engler, D.},
	month = may,
	year = {2006},
	keywords = {Buffer overflow, buffer overflow attack, Computer bugs, Computer crashes, computer viruses, Concrete, disk mounting code, ext2 file system, ext3 file system, file system code, file system image validation, File systems, invariant violations, Kernel, Laboratories, Linux, Linux file systems, malicious disk automatic generation, operating system kernel, Operating Systems, program debugging, symbolic execution, Testing},
	pages = {15 pp.--257},
	file = {IEEE Xplore Abstract Record:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JW7V2CKS/abs_all.html:text/html;Yang et al. - 2006 - Automatically generating malicious disks using sym.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/E9I9BG2W/Yang et al. - 2006 - Automatically generating malicious disks using sym.pdf:application/pdf}
}

@inproceedings{boyapati_korat:_2002,
	address = {New York, {NY}, {USA}},
	series = {{ISSTA} '02},
	title = {Korat: Automated Testing Based on Java Predicates},
	isbn = {1-58113-562-9},
	shorttitle = {Korat},
	url = {http://doi.acm.org/10.1145/566172.566191},
	doi = {10.1145/566172.566191},
	abstract = {This paper presents Korat, a novel framework for automated testing of Java programs. Given a formal specification for a method, Korat uses the method precondition to automatically generate all (nonisomorphic) test cases up to a given small size. Korat then executes the method on each test case, and uses the method postcondition as a test oracle to check the correctness of each output.To generate test cases for a method, Korat constructs a Java predicate (i.e., a method that returns a boolean) from the method's pre-condition. The heart of Korat is a technique for automatic test case generation: given a predicate and a bound on the size of its inputs, Korat generates all (nonisomorphic) inputs for which the predicate returns true. Korat exhaustively explores the bounded input space of the predicate but does so efficiently by monitoring the predicate's executions and pruning large portions of the search space.This paper illustrates the use of Korat for testing several data structures, including some from the Java Collections Framework. The experimental results show that it is feasible to generate test cases from Java predicates, even when the search space for inputs is very large. This paper also compares Korat with a testing framework based on declarative specifications. Contrary to our initial expectation, the experiments show that Korat generates test cases much faster than the declarative framework.},
	urldate = {2014-07-01},
	booktitle = {Proceedings of the 2002 {ACM} {SIGSOFT} International Symposium on Software Testing and Analysis},
	publisher = {{ACM}},
	author = {Boyapati, Chandrasekhar and Khurshid, Sarfraz and Marinov, Darko},
	year = {2002},
	keywords = {\_tablet},
	pages = {123--133},
	file = {Boyapati et al. - 2002 - Korat Automated Testing Based on Java Predicates.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/ANN5M4XC/Boyapati et al. - 2002 - Korat Automated Testing Based on Java Predicates.pdf:application/pdf}
}

@inproceedings{gabriel_structure_2012,
	title = {The structure of a programming language revolution},
	isbn = {9781450315623},
	url = {http://dl.acm.org/citation.cfm?doid=2384592.2384611},
	doi = {10.1145/2384592.2384611},
	abstract = {Engineering often precedes science. Incommensurability is real},
	booktitle = {Onward},
	publisher = {{ACM} Request Permissions},
	author = {Gabriel, Richard P},
	year = {2012},
	keywords = {\_tablet},
	pages = {195--214},
	file = {Gabriel - 2012 - The structure of a programming language revolution.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/6HK26BPB/Gabriel - 2012 - The structure of a programming language revolution.pdf:application/pdf}
}

@article{cadar_symbolic_2013,
	title = {Symbolic Execution for Software Testing: Three Decades Later},
	volume = {56},
	issn = {0001-0782},
	shorttitle = {Symbolic Execution for Software Testing},
	url = {http://doi.acm.org/10.1145/2408776.2408795},
	doi = {10.1145/2408776.2408795},
	abstract = {The challenges---and great promise---of modern symbolic execution techniques, and the tools to help implement them.},
	number = {2},
	urldate = {2015-01-22},
	journal = {Commun. {ACM}},
	author = {Cadar, Cristian and Sen, Koushik},
	month = feb,
	year = {2013},
	pages = {82--90},
	file = {Cadar and Sen - 2013 - Symbolic Execution for Software Testing Three Dec.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/CPHVWKMB/Cadar and Sen - 2013 - Symbolic Execution for Software Testing Three Dec.pdf:application/pdf}
}

@inproceedings{vazou_refinement_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Refinement Types for Haskell},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628161},
	doi = {10.1145/2628136.2628161},
	abstract = {{SMT}-based checking of refinement types for call-by-value languages is a well-studied subject. Unfortunately, the classical translation of refinement types to verification conditions is unsound under lazy evaluation. When checking an expression, such systems implicitly assume that all the free variables in the expression are bound to values. This property is trivially guaranteed by eager, but does not hold under lazy, evaluation. Thus, to be sound and precise, a refinement type system for Haskell and the corresponding verification conditions must take into account which subset of binders actually reduces to values. We present a stratified type system that labels binders as potentially diverging or not, and that (circularly) uses refinement types to verify the labeling. We have implemented our system in {LIQUIDHASKELL} and present an experimental evaluation of our approach on more than 10,000 lines of widely used Haskell libraries. We show that {LIQUIDHASKELL} is able to prove 96\% of all recursive functions terminating, while requiring a modest 1.7 lines of termination-annotations per 100 lines of code.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit and Vytiniotis, Dimitrios and Peyton-Jones, Simon},
	year = {2014},
	keywords = {\_tablet},
	pages = {269--282},
	file = {Vazou et al. - 2014 - Refinement Types for Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/CGNTUBFW/Vazou et al. - 2014 - Refinement Types for Haskell.pdf:application/pdf}
}

@inproceedings{torlak_growing_2013,
	address = {New York, {NY}, {USA}},
	series = {Onward! '13},
	title = {Growing Solver-aided Languages with Rosette},
	isbn = {978-1-4503-2472-4},
	url = {http://doi.acm.org/10.1145/2509578.2509586},
	doi = {10.1145/2509578.2509586},
	urldate = {2014-11-10},
	booktitle = {Proceedings of the 2013 {ACM} International Symposium on New Ideas, New Paradigms, and Reflections on Programming \&\#38; Software},
	publisher = {{ACM}},
	author = {Torlak, Emina and Bodik, Rastislav},
	year = {2013},
	keywords = {languages, solver-aided},
	pages = {135--152},
	file = {Torlak and Bodik - 2013 - Growing Solver-aided Languages with Rosette.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/7ER9DNQ3/Torlak and Bodik - 2013 - Growing Solver-aided Languages with Rosette.pdf:application/pdf}
}

@inproceedings{vazou_liquidhaskell:_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {{LiquidHaskell}: Experience with Refinement Types in the Real World},
	isbn = {978-1-4503-3041-1},
	shorttitle = {{LiquidHaskell}},
	url = {http://doi.acm.org/10.1145/2633357.2633366},
	doi = {10.1145/2633357.2633366},
	abstract = {Haskell has many delightful features. Perhaps the one most beloved by its users is its type system that allows developers to specify and verify a variety of program properties at compile time. However, many properties, typically those that depend on relationships between program values are impossible, or at the very least, cumbersome to encode within the existing type system. Many such properties can be verified using a combination of Refinement Types and external {SMT} solvers. We describe the refinement type checker {liquidHaskell}, which we have used to specify and verify a variety of properties of over 10,000 lines of Haskell code from various popular libraries, including containers, hscolour, bytestring, text, vector-algorithms and xmonad. First, we present a high-level overview of {liquidHaskell}, through a tour of its features. Second, we present a qualitative discussion of the kinds of properties that can be checked -- ranging from generic application independent criteria like totality and termination, to application specific concerns like memory safety and data structure correctness invariants. Finally, we present a quantitative evaluation of the approach, with a view towards measuring the efficiency and programmer effort required for verification, and discuss the limitations of the approach.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Vazou, Niki and Seidel, Eric L. and Jhala, Ranjit},
	year = {2014},
	keywords = {\_tablet, haskell, refinement types, smt-based verification, verification},
	pages = {39--51},
	file = {Vazou et al. - 2014 - LiquidHaskell Experience with Refinement Types in.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/IICVWSTF/Vazou et al. - 2014 - LiquidHaskell Experience with Refinement Types in.pdf:application/pdf}
}

@inproceedings{mainland_explicitly_2012,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '12},
	title = {Explicitly Heterogeneous Metaprogramming with {MetaHaskell}},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364572},
	doi = {10.1145/2364527.2364572},
	abstract = {Languages with support for metaprogramming, like {MetaOCaml}, offer a principled approach to code generation by guaranteeing that well-typed metaprograms produce well-typed programs. However, many problem domains where metaprogramming can fruitfully be applied require generating code in languages like C, {CUDA}, or assembly. Rather than resorting to add-hoc code generation techniques, these applications should be directly supported by explicitly heterogeneous metaprogramming languages. We present {MetaHaskell}, an extension of Haskell 98 that provides modular syntactic and type system support for type safe metaprogramming with multiple object languages. Adding a new object language to {MetaHaskell} requires only minor modifications to the host language to support type-level quantification over object language types and propagation of type equality constraints. We demonstrate the flexibility of our approach through three object languages: a core {ML} language, a linear variant of the core {ML} language, and a subset of C. All three languages support metaprogramming with open terms and guarantee that well-typed {MetaHaskell} programs will only produce closed object terms that are well-typed. The essence of {MetaHaskell} is captured in a type system for a simplified metalanguage. {MetaHaskell}, as well as all three object languages, are fully implemented in the mhc bytecode compiler.},
	urldate = {2015-01-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Mainland, Geoffrey},
	year = {2012},
	keywords = {linear languages, metaprogramming, open terms, quasiquotation, type systems},
	pages = {311--322},
	file = {Mainland - 2012 - Explicitly Heterogeneous Metaprogramming with Meta.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/546RAQ2N/Mainland - 2012 - Explicitly Heterogeneous Metaprogramming with Meta.pdf:application/pdf}
}

@inproceedings{lindley_algebraic_2014,
	address = {New York, {NY}, {USA}},
	series = {{WGP} '14},
	title = {Algebraic Effects and Effect Handlers for Idioms and Arrows},
	isbn = {978-1-4503-3042-8},
	url = {http://doi.acm.org/10.1145/2633628.2633636},
	doi = {10.1145/2633628.2633636},
	abstract = {Plotkin and Power's algebraic effects combined with Plotkin and Pretnar's effect handlers provide a foundation for modular programming with effects. We present a generalisation of algebraic effects and effect handlers to support other kinds of effectful computations corresponding to {McBride} and Paterson's idioms and Hughes' arrows.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 10th {ACM} {SIGPLAN} Workshop on Generic Programming},
	publisher = {{ACM}},
	author = {Lindley, Sam},
	year = {2014},
	keywords = {\_tablet, algebraic effects, applicative functors, arrows, call-by-push-value, effect handlers, idioms, monads},
	pages = {47--58},
	file = {Lindley - 2014 - Algebraic Effects and Effect Handlers for Idioms a.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/S5TECUR6/Lindley - 2014 - Algebraic Effects and Effect Handlers for Idioms a.pdf:application/pdf}
}

@inproceedings{gabriel_ultra-large-scale_2006,
	address = {New York, {NY}, {USA}},
	series = {{OOPSLA} '06},
	title = {Ultra-large-scale Systems},
	isbn = {1-59593-491-X},
	url = {http://doi.acm.org/10.1145/1176617.1176645},
	doi = {10.1145/1176617.1176645},
	abstract = {Scale changes everything. The trend in the design and development of software-intensive systems today is toward scale that increases in every measurable way. Lines of code, complexity, dependency, communication, bandwidth, memory, datasets, and many other measures for our systems continue to reach and exceed the limits of our ability to produce high-quality systems for all purposes.These systems will be unbounded, integrating internet-scale resources. They will serve diverse stakeholders with competing objectives and at the same time be constrained by policy, regulation, and the behaviors of their users. The lines between development, acquisition, and operations will blur: {ULS} systems will not die; they will be too large to be replaced and will be inextricably connected to the day-to-day mission. Rather, they will continue to evolve over time with behavior often more emergent than planned. Because complete specifications will not be achievable, sufficient assurance will have to do. {ULS} systems present "wicked problems," ones for which each attempt to create a solution changes the problem. Some of these characteristics appear in conventional systems, but in {ULS} systems they will dominate.},
	urldate = {2014-06-03},
	booktitle = {Companion to the 21st {ACM} {SIGPLAN} Symposium on Object-oriented Programming Systems, Languages, and Applications},
	publisher = {{ACM}},
	author = {Gabriel, Richard P. and Northrop, Linda and Schmidt, Douglas C. and Sullivan, Kevin},
	year = {2006},
	keywords = {\_tablet, design, methodology, systems, ultra-large-scale},
	pages = {632--634},
	file = {Gabriel et al. - 2006 - Ultra-large-scale Systems.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/W6TD6KV6/Gabriel et al. - 2006 - Ultra-large-scale Systems.pdf:application/pdf}
}

@inproceedings{okabe_systems_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Systems Demonstration: Writing {NetBSD} Sound Drivers in Haskell},
	isbn = {978-1-4503-3041-1},
	shorttitle = {Systems Demonstration},
	url = {http://doi.acm.org/10.1145/2633357.2633370},
	doi = {10.1145/2633357.2633370},
	abstract = {Most strongly typed, functional programming languages are not equipped with a reentrant garbage collector. Therefore such languages are not used for operating systems programming, where the virtues of types are most desired. We propose the use of Context-Local Heaps ({CLHs}) to achieve reentrancy, which also increasing the speed of garbage collection. We have implemented {CLHs} in Ajhc, a Haskell compiler derived from jhc, rewritten some {NetBSD} sound drivers using Ajhc, and benchmarked them. The reentrant, faster garbage collection that {CLHs} provide opens the path to type-assisted operating systems programming.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Okabe, Kiwamu and Muranushi, Takayuki},
	year = {2014},
	keywords = {\_tablet, languages, performance},
	pages = {77--78},
	file = {Okabe and Muranushi - 2014 - Systems Demonstration Writing NetBSD Sound Driver.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/JMD5FDPU/Okabe and Muranushi - 2014 - Systems Demonstration Writing NetBSD Sound Driver.pdf:application/pdf}
}

@inproceedings{ramsey_teaching_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {On Teaching *How to Design Programs*: Observations from a Newcomer},
	isbn = {978-1-4503-2873-9},
	shorttitle = {On Teaching *How to Design Programs*},
	url = {http://doi.acm.org/10.1145/2628136.2628137},
	doi = {10.1145/2628136.2628137},
	abstract = {This paper presents a personal, qualitative case study of a first course using How to Design Programs and its functional teaching languages. The paper reconceptualizes the book's six-step design process as an eight-step design process ending in a new "review and refactor" step. It recommends specific approaches to students' difficulties with function descriptions, function templates, data examples, and other parts of the design process. It connects the process to interactive "world programs." It recounts significant, informative missteps in course design and delivery. Finally, it identifies some unsolved teaching problems and some potential solutions.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Ramsey, Norman},
	year = {2014},
	keywords = {\_tablet, how to design programs, introductory programming course, program by design, racket, reflective practice},
	pages = {153--166},
	file = {Ramsey - 2014 - On Teaching How to Design Programs Observations.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9NTGIUSV/Ramsey - 2014 - On Teaching How to Design Programs Observations.pdf:application/pdf}
}

@inproceedings{ploeg_reflection_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Reflection Without Remorse: Revealing a Hidden Sequence to Speed Up Monadic Reflection},
	isbn = {978-1-4503-3041-1},
	shorttitle = {Reflection Without Remorse},
	url = {http://doi.acm.org/10.1145/2633357.2633360},
	doi = {10.1145/2633357.2633360},
	abstract = {A series of list appends or monadic binds for many monads performs algorithmically worse when left-associated. Continuation-passing style ({CPS}) is well-known to cure this severe dependence of performance on the association pattern. The advantage of {CPS} dwindles or disappears if we have to examine or modify the intermediate result of a series of appends or binds, before continuing the series. Such examination is frequently needed, for example, to control search in non-determinism monads. We present an alternative approach that is just as general as {CPS} but more robust: it makes series of binds and other such operations efficient regardless of the association pattern-- and also provides efficient access to intermediate results. The key is to represent such a conceptual sequence as an efficient sequence data structure. Efficient sequence data structures from the literature are homogeneous and cannot be applied as they are in a type-safe way to series of monadic binds. We generalize them to type aligned sequences and show how to construct their (assuredly order-preserving) implementations. We demonstrate that our solution solves previously undocumented, severe performance problems in iteratees, {LogicT} transformers, free monads and extensible effects.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Ploeg, Atze van der and Kiselyov, Oleg},
	year = {2014},
	keywords = {\_tablet, data structures, monads, performance, reflection},
	pages = {133--144},
	file = {Ploeg and Kiselyov - 2014 - Reflection Without Remorse Revealing a Hidden Seq.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XGJGI6A9/XGJGI6A9.pdf:application/pdf}
}

@inproceedings{lindblad_property_2007,
	series = {Trends in Functional Programming},
	title = {Property Directed Generation of First-Order Test Data},
	volume = {8},
	isbn = {978-1-84150-196-3},
	booktitle = {Proceedings of the Eighth Symposium on Trends in Functional Programming, {TFP} 2007, New York City, New York, {USA}, April 2-4. 2007},
	publisher = {Intellect},
	author = {Lindblad, Fredrik},
	editor = {Morazán, Marco T.},
	year = {2007},
	keywords = {\_tablet, research-exam},
	pages = {105--123},
	file = {Lindblad - 2007 - Property Directed Generation of First-Order Test D.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/MSPV6XBE/Lindblad - 2007 - Property Directed Generation of First-Order Test D.pdf:application/pdf}
}

@book{jackson_software_2006,
	title = {Software Abstractions: Logic, Language, and Analysis},
	isbn = {0262101149},
	shorttitle = {Software Abstractions},
	publisher = {The {MIT} Press},
	author = {Jackson, Daniel},
	year = {2006}
}

@inproceedings{xu_static_2009,
	title = {Static Contract Checking for Haskell},
	abstract = {Program errors are hard to detect and are costly both to programmers who spend significant efforts in debugging, and for systems that are guarded by runtime checks. Static verification techniques have been applied to imperative and object-oriented languages, like Java and C\#, but few have been applied to a higher-order lazy functional language, like Haskell. In this paper, we describe a sound and automatic static verification framework for Haskell, that is based on contracts and symbolic execution. Our approach is modular and gives precise blame assignments at compile-time in the presence of higher-order functions and laziness. D.3 [Software]: Program-},
	booktitle = {In Proceedings of the 36 th Annual {ACM} Symposium on the Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Xu, Dana N. and Jones, Simon Peyton and Claessen, Koen},
	year = {2009},
	pages = {41--52},
	file = {Citeseer - Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/C3G64W9W/summary.html:text/html;Xu et al. - 2009 - Static Contract Checking for Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/ZEQ4UZT4/Xu et al. - 2009 - Static Contract Checking for Haskell.pdf:application/pdf}
}

@inproceedings{marinov_testera:_2001,
	title = {{TestEra}: A novel framework for automated testing of Java programs},
	shorttitle = {{TestEra}},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=989787},
	urldate = {2014-09-09},
	booktitle = {Automated Software Engineering, 2001.({ASE} 2001). Proceedings. 16th Annual International Conference on},
	publisher = {{IEEE}},
	author = {Marinov, Darko and Khurshid, Sarfraz},
	year = {2001},
	keywords = {\_tablet},
	pages = {22--31},
	file = {Marinov and Khurshid - 2001 - TestEra A novel framework for automated testing o.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/4XSMBJ5I/Marinov and Khurshid - 2001 - TestEra A novel framework for automated testing o.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/XVX68WN8/login.html:text/html}
}

@phdthesis{nelson_techniques_1980,
	address = {Stanford, {CA}, {USA}},
	title = {Techniques for Program Verification},
	school = {Stanford University},
	author = {Nelson, Charles Gregory},
	year = {1980},
	note = {{AAI}8011683}
}

@article{hall_type_1996,
	title = {Type Classes in Haskell},
	volume = {18},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/227699.227700},
	doi = {10.1145/227699.227700},
	abstract = {This article defines a set of type inference rules for resolving overloading introduced by type classes, as used in the functional programming language Haskell. Programs including type classes are transformed into ones which may be typed by standard Hindley-Milner inference rules. In contrast to other work on type classes, the rules presented here relate directly to Haskell programs. An innovative aspect of this work is the use of second-order lambda calculus to record type information in the transformed program.},
	number = {2},
	urldate = {2014-07-17},
	journal = {{ACM} Trans. Program. Lang. Syst.},
	author = {Hall, Cordelia V. and Hammond, Kevin and Peyton Jones, Simon L. and Wadler, Philip L.},
	month = mar,
	year = {1996},
	keywords = {\_tablet, functional programming, haskell, type classes, types},
	pages = {109--138},
	file = {Hall et al. - 1996 - Type Classes in Haskell.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RPS3Z8FI/Hall et al. - 1996 - Type Classes in Haskell.pdf:application/pdf}
}

@inproceedings{majumdar_hybrid_2007,
	address = {Washington, {DC}, {USA}},
	series = {{ICSE} '07},
	title = {Hybrid Concolic Testing},
	isbn = {0-7695-2828-7},
	url = {http://dx.doi.org/10.1109/ICSE.2007.41},
	doi = {10.1109/ICSE.2007.41},
	abstract = {We present hybrid concolic testing, an algorithm that interleaves random testing with concolic execution to obtain both a deep and a wide exploration of program state space. Our algorithm generates test inputs automatically by interleaving random testing until saturation with bounded exhaustive symbolic exploration of program points. It thus combines the ability of random search to reach deep program states quickly together with the ability of concolic testing to explore states in a neighborhood exhaustively. We have implemented our algorithm on top of {CUTE} and applied it to obtain better branch coverage for an editor implementation ({VIM} 5.7, 150K lines of code) as well as a data structure implementation in C. Our experiments suggest that hybrid concolic testing can handle large programs and provide, for the same testing budget, almost 4× the branch coverage than random testing and almost 2× that of concolic testing.},
	urldate = {2014-06-16},
	booktitle = {Proceedings of the 29th International Conference on Software Engineering},
	publisher = {{IEEE} Computer Society},
	author = {Majumdar, Rupak and Sen, Koushik},
	year = {2007},
	keywords = {\_tablet, concolic testing., directed random testing, research-exam},
	pages = {416--426},
	file = {Majumdar and Sen - 2007 - Hybrid Concolic Testing.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/ICRU7PZM/Majumdar and Sen - 2007 - Hybrid Concolic Testing.pdf:application/pdf}
}

@inproceedings{godefroid_compositional_2007,
	address = {New York, {NY}, {USA}},
	series = {{POPL} '07},
	title = {Compositional Dynamic Test Generation},
	isbn = {1-59593-575-4},
	url = {http://doi.acm.org/10.1145/1190216.1190226},
	doi = {10.1145/1190216.1190226},
	abstract = {Dynamic test generation is a form of dynamic program analysis that attempts to compute test inputs to drive a program along a specific program path. Directed Automated Random Testing, or {DART} for short, blends dynamic test generation with model checking techniques with the goal of systematically executing all feasible program paths of a program while detecting various types of errors using run-time checking tools (like Purify, for instance). Unfortunately, systematically executing all feasible program paths does not scale to large, realistic programs.This paper addresses this major limitation and proposes to perform dynamic test generation compositionally, by adapting known techniques for interprocedural static analysis. Specifically, we introduce a new algorithm, dubbed {SMART} for Systematic Modular Automated Random Testing, that extends {DART} by testing functions in isolation, encoding test results as function summaries expressed using input preconditions and output postconditions, and then re-using those summaries when testing higher-level functions. We show that, for a fixed reasoning capability, our compositional approach to dynamic test generation ({SMART}) is both sound and complete compared to monolithic dynamic test generation ({DART}). In other words, {SMART} can perform dynamic test generation compositionally without any reduction in program path coverage. We also show that, given a bound on the maximum number of feasible paths in individual program functions, the number of program executions explored by {SMART} is linear in that bound, while the number of program executions explored by {DART} can be exponential in that bound. We present examples of C programs and preliminary experimental results that illustrate and validate empirically these properties.},
	urldate = {2015-01-23},
	booktitle = {Proceedings of the 34th Annual {ACM} {SIGPLAN}-{SIGACT} Symposium on Principles of Programming Languages},
	publisher = {{ACM}},
	author = {Godefroid, Patrice},
	year = {2007},
	keywords = {automatic test generation, compositional program analysis, program verification, scalability, software testing},
	pages = {47--54},
	file = {Godefroid - 2007 - Compositional Dynamic Test Generation.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/3V8679H2/Godefroid - 2007 - Compositional Dynamic Test Generation.pdf:application/pdf}
}

@inproceedings{ray_large_2014,
	address = {New York, {NY}, {USA}},
	series = {{FSE} 2014},
	title = {A Large Scale Study of Programming Languages and Code Quality in Github},
	isbn = {978-1-4503-3056-5},
	url = {http://doi.acm.org/10.1145/2635868.2635922},
	doi = {10.1145/2635868.2635922},
	abstract = {What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from {GitHub} (729 projects, 80 Million {SLOC}, 29,000 authors, 1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach, combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static v.s. dynamic typing, strong v.s. weak typing on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant, but modest effect on software quality. Most notably, it does appear that strong typing is modestly better than weak typing, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size, team size, and commit size. However, we hasten to caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, e.g., the preference of certain personality types for functional, static and strongly typed languages.},
	urldate = {2015-01-21},
	booktitle = {Proceedings of the 22Nd {ACM} {SIGSOFT} International Symposium on Foundations of Software Engineering},
	publisher = {{ACM}},
	author = {Ray, Baishakhi and Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar},
	year = {2014},
	keywords = {bug fix, code quality, empirical research, programming language, regression analysis, software domain, type system},
	pages = {155--165}
}

@inproceedings{wu_effect_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {Effect Handlers in Scope},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633358},
	doi = {10.1145/2633357.2633358},
	abstract = {Algebraic effect handlers are a powerful means for describing effectful computations. They provide a lightweight and orthogonal technique to define and compose the syntax and semantics of different effects. The semantics is captured by handlers, which are functions that transform syntax trees. Unfortunately, the approach does not support syntax for scoping constructs, which arise in a number of scenarios. While handlers can be used to provide a limited form of scope, we demonstrate that this approach constrains the possible interactions of effects and rules out some desired semantics. This paper presents two different ways to capture scoped constructs in syntax, and shows how to achieve different semantics by reordering handlers. The first approach expresses scopes using the existing algebraic handlers framework, but has some limitations. The problem is fully solved in the second approach where we introduce higher-order syntax.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Wu, Nicolas and Schrijvers, Tom and Hinze, Ralf},
	year = {2014},
	keywords = {\_tablet, effect handlers, haskell, Modularity, monads, semantics, syntax},
	pages = {1--12},
	file = {Wu et al. - 2014 - Effect Handlers in Scope.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/R8ZA44I5/Wu et al. - 2014 - Effect Handlers in Scope.pdf:application/pdf}
}

@inproceedings{perera_functional_2012,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '12},
	title = {Functional Programs That Explain Their Work},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364579},
	doi = {10.1145/2364527.2364579},
	abstract = {We present techniques that enable higher-order functional computations to "explain" their work by answering questions about how parts of their output were calculated. As explanations, we consider the traditional notion of program slices, which we show can be inadequate, and propose a new notion: trace slices. We present techniques for specifying flexible and rich slicing criteria based on partial expressions, parts of which have been replaced by holes. We characterise program slices in an algorithm-independent fashion and show that a least slice for a given criterion exists. We then present an algorithm, called unevaluation, for computing least program slices from computations reified as traces. Observing a limitation of program slices, we develop a notion of trace slice as another form of explanation and present an algorithm for computing them. The unevaluation algorithm can be applied to any subtrace of a trace slice to compute a program slice whose evaluation generates that subtrace. This close correspondence between programs, traces, and their slices can enable the programmer to understand a computation interactively, in terms of the programming language in which the computation is expressed. We present an implementation in the form of a tool, discuss some important practical implementation concerns and present some techniques for addressing them.},
	urldate = {2015-01-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Perera, Roly and Acar, Umut A. and Cheney, James and Levy, Paul Blain},
	year = {2012},
	keywords = {debugging, program slicing, provenance},
	pages = {365--376},
	file = {Perera et al. - 2012 - Functional Programs That Explain Their Work.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RCZUAB42/Perera et al. - 2012 - Functional Programs That Explain Their Work.pdf:application/pdf}
}

@inproceedings{hickey_building_2014,
	address = {New York, {NY}, {USA}},
	series = {{ICFP} '14},
	title = {Building Embedded Systems with Embedded {DSLs}},
	isbn = {978-1-4503-2873-9},
	url = {http://doi.acm.org/10.1145/2628136.2628146},
	doi = {10.1145/2628136.2628146},
	abstract = {We report on our experiences in synthesizing a fully-featured autopilot from embedded domain-specific languages ({EDSLs}) hosted in Haskell. The autopilot is approximately 50k lines of C code generated from 10k lines of {EDSL} code and includes control laws, mode logic, encrypted communications system, and device drivers. The autopilot was built in less than two engineer years. This is the story of how {EDSLs} provided the productivity and safety gains to do large-scale low-level embedded programming and lessons we learned in doing so.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} International Conference on Functional Programming},
	publisher = {{ACM}},
	author = {Hickey, Patrick C. and Pike, Lee and Elliott, Trevor and Bielman, James and Launchbury, John},
	year = {2014},
	keywords = {\_tablet, embedded domain specific languages, embedded systems},
	pages = {3--9},
	file = {Hickey et al. - 2014 - Building Embedded Systems with Embedded DSLs.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/CCNXRUWP/Hickey et al. - 2014 - Building Embedded Systems with Embedded DSLs.pdf:application/pdf}
}

@inproceedings{morris_simple_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {A Simple Semantics for Haskell Overloading},
	isbn = {978-1-4503-3041-1},
	url = {http://doi.acm.org/10.1145/2633357.2633364},
	doi = {10.1145/2633357.2633364},
	abstract = {As originally proposed, type classes provide overloading and ad-hoc definition, but can still be understood (and implemented) in terms of strictly parametric calculi. This is not true of subsequent extensions of type classes. Functional dependencies and equality constraints allow the satisfiability of predicates to refine typing; this means that the interpretations of equivalent qualified types may not be interconvertible. Overlapping instances and instance chains allow predicates to be satisfied without determining the implementations of their associated class methods, introducing truly non-parametric behavior. We propose a new approach to the semantics of type classes, interpreting polymorphic expressions by the behavior of each of their ground instances, but without requiring that those behaviors be parametrically determined. We argue that this approach both matches the intuitive meanings of qualified types and accurately models the behavior of programs.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Morris, J. Garrett},
	year = {2014},
	keywords = {\_tablet, overloading, semantics, type classes},
	pages = {107--118},
	file = {Morris - 2014 - A Simple Semantics for Haskell Overloading.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/G6FGKNKS/Morris - 2014 - A Simple Semantics for Haskell Overloading.pdf:application/pdf}
}

@incollection{tsushima_embedded_2013,
	series = {Lecture Notes in Computer Science},
	title = {An Embedded Type Debugger},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-41581-4, 978-3-642-41582-1},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-41582-1_12},
	abstract = {This paper presents how to build a type debugger without implementing any dedicated type inferencer. Previous type debuggers required their own type inferencers apart from the compiler’s type inferencer. The advantage of our approach is threefold. First, by not implementing a type inferencer, it is guaranteed that the debugger’s type inference never disagrees with the compiler’s type inference. Secondly, we can avoid the pointless reproduction of a type inferencer that should work precisely as the compiler’s type inferencer. Thirdly, our approach is robust to updates of the underlying language. The key observation of our approach is that the interactive type debugging, as proposed by Chitil, does not require a type inference tree but only a tree with a certain simple property. We identify the property and present how to construct a tree that satisfies this property using the compiler’s type inferencer. The property guides us how to build a type debugger for various language constructs. In this paper, we describe our idea and first apply it to the simply-typed lambda calculus. After that, we extend it with let-polymorphism and objects to see how our technique scales.},
	language = {en},
	urldate = {2014-06-04},
	booktitle = {Implementation and Application of Functional Languages},
	publisher = {Springer Berlin Heidelberg},
	author = {Tsushima, Kanae and Asai, Kenichi},
	editor = {Hinze, Ralf},
	month = jan,
	year = {2013},
	keywords = {\_tablet, Information Systems Applications (incl. Internet), Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {190--206},
	file = {Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/FUXJ7N9F/978-3-642-41582-1_12.html:text/html;Tsushima and Asai - 2013 - An Embedded Type Debugger.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/DZFHDZCK/Tsushima and Asai - 2013 - An Embedded Type Debugger.pdf:application/pdf}
}

@inproceedings{allen_component_2010,
	title = {Component specification in the Cactus Framework: The Cactus Configuration Language},
	isbn = {978-1-4244-9347-0},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5698008},
	doi = {10.1109/GRID.2010.5698008},
	abstract = {Component frameworks are complex systems that rely on many layers of abstraction to function properly. One essential requirement is a consistent means of describing each individual component and how it relates to both other components and the whole f...},
	booktitle = {{GRID}},
	publisher = {{IEEE}},
	author = {Allen, Gabrielle and Löffler, Frank and Schnetter, Erik and Seidel, Eric L},
	year = {2010},
	keywords = {\_tablet},
	pages = {359--368},
	file = {Allen et al. - 2010 - Component specification in the Cactus Framework T.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/338NBCV5/Allen et al. - 2010 - Component specification in the Cactus Framework T.pdf:application/pdf}
}

@inproceedings{pike_smartcheck:_2014,
	address = {New York, {NY}, {USA}},
	series = {Haskell '14},
	title = {{SmartCheck}: Automatic and Efficient Counterexample Reduction and Generalization},
	isbn = {978-1-4503-3041-1},
	shorttitle = {{SmartCheck}},
	url = {http://doi.acm.org/10.1145/2633357.2633365},
	doi = {10.1145/2633357.2633365},
	abstract = {{QuickCheck} is a powerful library for automatic test-case generation. Because {QuickCheck} performs random testing, some of the counterexamples discovered are very large. {QuickCheck} provides an interface for the user to write shrink functions to attempt to reduce the size of counter examples. Hand-written implementations of shrink can be complex, inefficient, and consist of significant boilerplate code. Furthermore, shrinking is only one aspect in debugging: counterexample generalization is the process of extrapolating from individual counterexamples to a class of counterexamples, often requiring a flash of insight from the programmer. To improve counterexample reduction and generalization, we introduce {SmartCheck}. {SmartCheck} is a debugging tool that reduces algebraic data using generic search heuristics to efficiently find smaller counterexamples. In addition to shrinking, {SmartCheck} also automatically generalizes counterexamples to formulas representing classes of counterexamples. {SmartCheck} has been implemented for Haskell and is freely available.},
	urldate = {2014-09-06},
	booktitle = {Proceedings of the 2014 {ACM} {SIGPLAN} Symposium on Haskell},
	publisher = {{ACM}},
	author = {Pike, Lee},
	year = {2014},
	keywords = {\_tablet, delta-debugging, property-based testing, test-case generalization},
	pages = {53--64},
	file = {Pike - 2014 - SmartCheck Automatic and Efficient Counterexample.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/MP3TQAP9/Pike - 2014 - SmartCheck Automatic and Efficient Counterexample.pdf:application/pdf}
}

@incollection{claessen_quickspec:_2010,
	series = {Lecture Notes in Computer Science},
	title = {{QuickSpec}: Guessing Formal Specifications Using Testing},
	copyright = {©2010 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-13976-5, 978-3-642-13977-2},
	shorttitle = {{QuickSpec}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-13977-2_3},
	abstract = {We present {QuickSpec}, a tool that automatically generates algebraic specifications for sets of pure functions. The tool is based on testing, rather than static analysis or theorem proving. The main challenge {QuickSpec} faces is to keep the number of generated equations to a minimum while maintaining completeness. We demonstrate how {QuickSpec} can improve one’s understanding of a program module by exploring the laws that are generated using two case studies: a heap library for Haskell and a fixed-point arithmetic library for Erlang.},
	number = {6143},
	urldate = {2014-06-16},
	booktitle = {Tests and Proofs},
	publisher = {Springer Berlin Heidelberg},
	author = {Claessen, Koen and Smallbone, Nicholas and Hughes, John},
	editor = {Fraser, Gordon and Gargantini, Angelo},
	month = jan,
	year = {2010},
	keywords = {\_tablet, Algorithm Analysis and Problem Complexity, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, research-exam, Software Engineering, testing},
	pages = {6--21},
	file = {Claessen et al. - 2010 - QuickSpec Guessing Formal Specifications Using Te.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/RQTENUXJ/Claessen et al. - 2010 - QuickSpec Guessing Formal Specifications Using Te.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/V2APTV53/10.html:text/html}
}

@article{khurshid_testera:_2004,
	title = {{TestEra}: Specification-based testing of Java programs using {SAT}},
	volume = {11},
	shorttitle = {{TestEra}},
	url = {http://link.springer.com/article/10.1023/B:AUSE.0000038938.10589.b9},
	number = {4},
	urldate = {2014-09-09},
	journal = {Automated Software Engineering},
	author = {Khurshid, Sarfraz and Marinov, Darko},
	year = {2004},
	keywords = {\_tablet},
	pages = {403--434},
	file = {Khurshid and Marinov - 2004 - TestEra Specification-based testing of Java progr.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/IGRPDWAF/Khurshid and Marinov - 2004 - TestEra Specification-based testing of Java progr.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/6F3TZ7XM/BAUSE.0000038938.10589.html:text/html}
}

@inproceedings{ko_designing_2004,
	title = {Designing the whyline: a debugging interface for asking questions about program behavior},
	url = {http://portal.acm.org/citation.cfm?id=985692.985712&coll=DL&dl=ACM&CFID=445834110&CFTOKEN=55622119},
	doi = {10.1145/985692.985712},
	booktitle = {{CHI}},
	publisher = {{ACM} Request Permissions},
	author = {Ko, Andrew J and Myers, Brad A},
	year = {2004},
	keywords = {\_tablet},
	file = {Ko and Myers - 2004 - Designing the whyline a debugging interface for a.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/SZK5A4M7/Ko and Myers - 2004 - Designing the whyline a debugging interface for a.pdf:application/pdf}
}

@inproceedings{dunfield_refined_2007,
	address = {New York, {NY}, {USA}},
	series = {{PLPV} '07},
	title = {Refined Typechecking with Stardust},
	isbn = {978-1-59593-677-6},
	url = {http://doi.acm.org/10.1145/1292597.1292602},
	doi = {10.1145/1292597.1292602},
	abstract = {We present Stardust, an implementation of a type system for a subset of {ML} with type refinements, intersection types, and union types, enabling programmers to legibly specify certain classes of program invariants that are verified at compile time. This is the first implementation of unrestricted intersection and union types in a mainstream functional programming setting, as well as the first implementation of a system with both datasort and index refinements. The system-with the assistance of external constraint solvers-supports integer, Boolean and dimensional index refinements; we apply both value refinements (to check red-black tree invariants) and invaluable refinements (to check dimensional consistency). While typechecking with intersection and union types is intrinsically complex, our experience so far suggests that it can be practical in many instances.},
	urldate = {2014-07-02},
	booktitle = {Proceedings of the 2007 Workshop on Programming Languages Meets Program Verification},
	publisher = {{ACM}},
	author = {Dunfield, Joshua},
	year = {2007},
	keywords = {\_tablet, dependent types, intersection types, type refinements, union types},
	pages = {21--32},
	file = {Dunfield - 2007 - Refined Typechecking with Stardust.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/EJ33X8WA/Dunfield - 2007 - Refined Typechecking with Stardust.pdf:application/pdf}
}

@inproceedings{tucker_opium:_2007,
	address = {Washington, {DC}, {USA}},
	series = {{ICSE} '07},
	title = {{OPIUM}: Optimal Package Install/Uninstall Manager},
	isbn = {0-7695-2828-7},
	shorttitle = {{OPIUM}},
	url = {http://dx.doi.org/10.1109/ICSE.2007.59},
	doi = {10.1109/ICSE.2007.59},
	abstract = {Linux distributions often include package management tools such as apt-get in Debian or yum in {RedHat}. Using information about package dependencies and conflicts, such tools can determine how to install a new package (and its dependencies) on a system of already installed packages. Using off-the-shelf {SAT} solvers, pseudo-boolean solvers, and Integer Linear Programming solvers, we have developed a new package-management tool, called Opium, that improves on current tools in two ways: (1) Opium is complete, in that if there is a solution, Opium is guaranteed to find it, and (2) Opium can optimize a user-provided objective function, which could for example state that smaller packages should be preferred over larger ones. We performed a comparative study of our tool against Debian's apt-get on 600 traces of real-world package installations. We show that Opium runs fast enough to be usable, and that its completeness and optimality guarantees provide concrete benefits to end users.},
	urldate = {2014-06-12},
	booktitle = {Proceedings of the 29th International Conference on Software Engineering},
	publisher = {{IEEE} Computer Society},
	author = {Tucker, Chris and Shuffelton, David and Jhala, Ranjit and Lerner, Sorin},
	year = {2007},
	keywords = {\_tablet},
	pages = {178--188},
	file = {Tucker et al. - 2007 - OPIUM Optimal Package InstallUninstall Manager.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/M2F8CMUH/Tucker et al. - 2007 - OPIUM Optimal Package InstallUninstall Manager.pdf:application/pdf}
}

@incollection{ganesh_decision_2007,
	series = {Lecture Notes in Computer Science},
	title = {A Decision Procedure for Bit-Vectors and Arrays},
	copyright = {©2007 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-73367-6, 978-3-540-73368-3},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-73368-3_52},
	abstract = {{STP} is a decision procedure for the satisfiability of quantifier-free formulas in the theory of bit-vectors and arrays that has been optimized for large problems encountered in software analysis applications. The basic architecture of the procedure consists of word-level pre-processing algorithms followed by translation to {SAT}. The primary bottlenecks in software verification and bug finding applications are large arrays and linear bit-vector arithmetic. New algorithms based on the abstraction-refinement paradigm are presented for reasoning about large arrays. A solver for bit-vector linear arithmetic is presented that eliminates variables and parts of variables to enable other transformations, and reduce the size of the problem that is eventually received by the {SAT} solver. These and other algorithms have been implemented in {STP}, which has been heavily tested over thousands of examples obtained from several real-world applications. Experimental results indicate that the above mix of algorithms along with the overall architecture is far more effective, for a variety of applications, than a direct translation of the original formula to {SAT} or other comparable decision procedures.},
	language = {en},
	number = {4590},
	urldate = {2015-01-23},
	booktitle = {Computer Aided Verification},
	publisher = {Springer Berlin Heidelberg},
	author = {Ganesh, Vijay and Dill, David L.},
	editor = {Damm, Werner and Hermanns, Holger},
	year = {2007},
	keywords = {Artificial Intelligence (incl. Robotics), Logic Design, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Software Engineering},
	pages = {519--531},
	file = {Ganesh and Dill - 2007 - A Decision Procedure for Bit-Vectors and Arrays.pdf:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/BT5X3GJG/Ganesh and Dill - 2007 - A Decision Procedure for Bit-Vectors and Arrays.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Zotero/Profiles/s3pkbp8i.default/zotero/storage/9FMI9C68/10.html:text/html}
}